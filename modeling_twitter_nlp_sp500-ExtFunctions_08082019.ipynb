{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs_ds v. 0.7.4 ... read the docs at https://bs-ds.readthedocs.io/en/latest/index.html\n",
      "For convenient loading of standard modules :\n",
      ">> from bs_ds.imports import *\n",
      "\n",
      "display.max_columns=None\n",
      "display.expand_frame_repr=False\n",
      "display.max_rows=None\n",
      "display.max_info_columns=500\n",
      "display.precision=4\n",
      "For detailed help as well as source code, use `ihelp(function)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\james\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import bs_ds as bs\n",
    "bs.big_pandas()\n",
    "\n",
    "from functions_combined_BEST import ihelp,get_day_window_size_from_freq,custom_BH_freq, set_timeindex_freq,check_null_times\n",
    "from functions_combined_BEST import plot_time_series, load_stock_price_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     2,
     24,
     30,
     116,
     126,
     156,
     242
    ]
   },
   "outputs": [],
   "source": [
    "#################### TIMEINDEX FUNCTIONS #####################\n",
    "if skip==False:\n",
    "    def get_day_window_size_from_freq(dataset):#, freq='CBH'):\n",
    "\n",
    "        if dataset.index.freq == custom_BH_freq():\n",
    "            return 7\n",
    "\n",
    "        if dataset.index.freq=='T':\n",
    "            day_window_size = 60*24\n",
    "        elif dataset.index.freq=='BH':\n",
    "            day_window_size = 8\n",
    "    #     elif dataset.index.freq=='CBH':\n",
    "    #         day_window_size = 7\n",
    "        elif dataset.index.freq=='B':\n",
    "            day_window_size=1\n",
    "        elif dataset.index.freq=='D':\n",
    "            day_window_size=1\n",
    "\n",
    "        else:\n",
    "            raise Exception('dataset freq=None')\n",
    "\n",
    "        return day_window_size\n",
    "\n",
    "\n",
    "    def custom_BH_freq():\n",
    "        import pandas as pd\n",
    "        CBH = pd.tseries.offsets.CustomBusinessHour(start='09:30',end='16:30')\n",
    "        return CBH\n",
    "\n",
    "\n",
    "    def  set_timeindex_freq(ive_df, col_to_fill=None, freq='CBH',fill_method='ffill',\n",
    "                            verbose=3): #set_tz=True,\n",
    "\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "\n",
    "\n",
    "        if verbose>1:\n",
    "            # print(f\"{'Index When:':>{10}}\\t{'Freq:':>{20}}\\t{'Index Start:':>{40}}\\t{'Index End:':>{40}}\")\n",
    "            print(f\"{'Index When:'}\\t{'Freq:'}\\t{'Index Start'}\\t\\t{'Index End:'}\")\n",
    "            print(f\"Pre-Change\\t{ive_df.index.freq}\\t{ive_df.index[0]}\\t{ive_df.index[-1]}\")\n",
    "\n",
    "\n",
    "        if freq=='CBH':\n",
    "            freq=custom_BH_freq()\n",
    "    #         start_idx = \n",
    "\n",
    "        # Change frequency to freq\n",
    "        ive_df = ive_df.asfreq(freq,)#'min')\n",
    "\n",
    "        #     # Set timezone\n",
    "        #     if set_tz==True:\n",
    "        #         ive_df.tz_localize()\n",
    "        #         ive_df.index = ive_df.index.tz_convert('America/New_York')\n",
    "\n",
    "        # Report Success / Details\n",
    "        if verbose>1:\n",
    "            print(f\"Post-Change\\t{ive_df.index.freq}\\t{ive_df.index[0]}\\t{ive_df.index[-1]}\")\n",
    "\n",
    "\n",
    "        ## FILL AND TRACK TIMEPOINTS WITH MISSING DATA    \n",
    "\n",
    "        # Helper Function for adding column to track the datapoints that were filled\n",
    "        def check_null_times(x):\n",
    "            import numpy as np\n",
    "            if np.isnan(x):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        ## CREATE A COLUMN TO TRACK ROWS TO BE FILLED\n",
    "        # If col_to_fill provided, use that column to create/judge ive_df['filled_timebin'] \n",
    "        if col_to_fill!=None:\n",
    "            ive_df['filled_timebin'] = ive_df[col_to_fill].apply(lambda x: check_null_times(x))#True if ive_df.isna().any()\n",
    "\n",
    "        # if not provided, use all columns and sum results\n",
    "        elif col_to_fill == None:\n",
    "            # Prefill fol with 0's\n",
    "            ive_df['filled_timebin']=0\n",
    "\n",
    "            # loop through all columns and add results of check_null_times from each loop\n",
    "        for col in ive_df.columns:\n",
    "            if ive_df[col].dtypes=='float64':\n",
    "                #ive_df['filled_timebin'] = ive_df[target_col].apply(lambda x: check_null_times(x))#True if ive_df.isna().any()\n",
    "                curr_filled_timebin_col = ive_df[col].apply(lambda x: check_null_times(x))#True if ive_df.isna().any() \n",
    "\n",
    "                # add results\n",
    "                ive_df['filled_timebin'] +=  curr_filled_timebin_col\n",
    "\n",
    "        ive_df['filled_timebin'] = ive_df['filled_timebin'] >0\n",
    "\n",
    "        ## FILL IN NULL VALUES\n",
    "        ive_df.fillna(method=fill_method, inplace=True)\n",
    "\n",
    "        # Report # filled\n",
    "        if verbose>0:\n",
    "            check_fill = ive_df.loc[ive_df['filled_timebin']>0]\n",
    "            print(f'\\nFilled {len(check_fill==True)}# of rows using method {fill_method}')\n",
    "\n",
    "        # Report any remaning null values\n",
    "        if verbose>0:\n",
    "            res = ive_df.isna().sum()\n",
    "            if res.any():\n",
    "                print(f'Cols with Nulls:')\n",
    "                print(res[res>0])\n",
    "            else:\n",
    "                print('No Remaining Null Values')   \n",
    "\n",
    "        # display header\n",
    "        if verbose>2:\n",
    "            display(ive_df.head())\n",
    "\n",
    "        return ive_df\n",
    "\n",
    "\n",
    "    # Helper Function for adding column to track the datapoints that were filled\n",
    "    def check_null_times(x):\n",
    "        import numpy as np\n",
    "        if np.isnan(x):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    ############### TIMESERIES TESTS AND VISUALS ###############\n",
    "\n",
    "    def plot_time_series(stocks_df, freq=None, fill_method='ffill',figsize=(12,4)):\n",
    "\n",
    "        df = stocks_df.copy()\n",
    "        df.fillna(method=fill_method, inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        if (df.index.freq==None) & (freq == None):\n",
    "            xlabels=f'Time'\n",
    "\n",
    "        elif (df.index.freq==None) & (freq != None):\n",
    "            df = df.asfreq(freq)\n",
    "            df.fillna(method=fill_method, inplace=True)\n",
    "            df.dropna(inplace=True)\n",
    "            xlabels=f'Time - Frequency = {freq}'\n",
    "\n",
    "        else:\n",
    "            xlabels=f'Time - Frequency = {df.index.freq}'\n",
    "\n",
    "        ylabels=\"Price\"\n",
    "\n",
    "        raw_plot = df.plot(figsize=figsize)\n",
    "        raw_plot.set_title('Stock Bid Closing Price ')\n",
    "        raw_plot.set_ylabel(ylabels)\n",
    "        raw_plot.set_xlabel(xlabels)\n",
    "\n",
    "\n",
    "    #################### TIMEINDEX FUNCTIONS #####################\n",
    "\n",
    "\n",
    "\n",
    "    def  set_timeindex_freq(ive_df, col_to_fill=None, freq='CBH',fill_method='ffill',\n",
    "                            verbose=3): #set_tz=True,\n",
    "\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "\n",
    "\n",
    "        if verbose>1:\n",
    "            # print(f\"{'Index When:':>{10}}\\t{'Freq:':>{20}}\\t{'Index Start:':>{40}}\\t{'Index End:':>{40}}\")\n",
    "            print(f\"{'Index When:'}\\t{'Freq:'}\\t{'Index Start'}\\t\\t{'Index End:'}\")\n",
    "            print(f\"Pre-Change\\t{ive_df.index.freq}\\t{ive_df.index[0]}\\t{ive_df.index[-1]}\")\n",
    "\n",
    "\n",
    "        if freq=='CBH':\n",
    "            freq=custom_BH_freq()\n",
    "    #         start_idx = \n",
    "\n",
    "        # Change frequency to freq\n",
    "        ive_df = ive_df.asfreq(freq,)#'min')\n",
    "\n",
    "        #     # Set timezone\n",
    "        #     if set_tz==True:\n",
    "        #         ive_df.tz_localize()\n",
    "        #         ive_df.index = ive_df.index.tz_convert('America/New_York')\n",
    "\n",
    "        # Report Success / Details\n",
    "        if verbose>1:\n",
    "            print(f\"Post-Change\\t{ive_df.index.freq}\\t{ive_df.index[0]}\\t{ive_df.index[-1]}\")\n",
    "\n",
    "\n",
    "        ## FILL AND TRACK TIMEPOINTS WITH MISSING DATA    \n",
    "\n",
    "        # Helper Function for adding column to track the datapoints that were filled\n",
    "        def check_null_times(x):\n",
    "            import numpy as np\n",
    "            if np.isnan(x):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        ## CREATE A COLUMN TO TRACK ROWS TO BE FILLED\n",
    "        # If col_to_fill provided, use that column to create/judge ive_df['filled_timebin'] \n",
    "        if col_to_fill!=None:\n",
    "            ive_df['filled_timebin'] = ive_df[col_to_fill].apply(lambda x: check_null_times(x))#True if ive_df.isna().any()\n",
    "\n",
    "        # if not provided, use all columns and sum results\n",
    "        elif col_to_fill == None:\n",
    "            # Prefill fol with 0's\n",
    "            ive_df['filled_timebin']=0\n",
    "\n",
    "            # loop through all columns and add results of check_null_times from each loop\n",
    "        for col in ive_df.columns:\n",
    "            if ive_df[col].dtypes=='float64':\n",
    "                #ive_df['filled_timebin'] = ive_df[target_col].apply(lambda x: check_null_times(x))#True if ive_df.isna().any()\n",
    "                curr_filled_timebin_col = ive_df[col].apply(lambda x: check_null_times(x))#True if ive_df.isna().any() \n",
    "\n",
    "                # add results\n",
    "                ive_df['filled_timebin'] +=  curr_filled_timebin_col\n",
    "\n",
    "        ive_df['filled_timebin'] = ive_df['filled_timebin'] >0\n",
    "\n",
    "        ## FILL IN NULL VALUES\n",
    "        ive_df.fillna(method=fill_method, inplace=True)\n",
    "\n",
    "        # Report # filled\n",
    "        if verbose>0:\n",
    "            check_fill = ive_df.loc[ive_df['filled_timebin']>0]\n",
    "            print(f'\\nFilled {len(check_fill==True)}# of rows using method {fill_method}')\n",
    "\n",
    "        # Report any remaning null values\n",
    "        if verbose>0:\n",
    "            res = ive_df.isna().sum()\n",
    "            if res.any():\n",
    "                print(f'Cols with Nulls:')\n",
    "                print(res[res>0])\n",
    "            else:\n",
    "                print('No Remaining Null Values')   \n",
    "\n",
    "        # display header\n",
    "        if verbose>2:\n",
    "            display(ive_df.head())\n",
    "\n",
    "        return ive_df\n",
    "\n",
    "\n",
    "    # Helper Function for adding column to track the datapoints that were filled\n",
    "    def check_null_times(x):\n",
    "        import numpy as np\n",
    "        if np.isnan(x):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING STOCK DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-01-23 09:30:00    96.23\n",
       "2017-01-23 09:31:00    96.19\n",
       "2017-01-23 09:32:00    96.24\n",
       "2017-01-23 09:33:00    96.30\n",
       "2017-01-23 09:34:00    96.27\n",
       "Name: stock_price, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21599c23128>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import datetime as dt\n",
    "\n",
    "# skip=True\n",
    "\n",
    "if skip==False:\n",
    "    stock_df = pd.read_csv('data/stock_df_with_tech_indicators_CBH_index.csv')#, index_col=0, parse_dates=True)\n",
    "    stock_df['date'] = pd.to_datetime(stock_df['Unnamed: 0'])\n",
    "    stock_df.drop('Unnamed: 0',axis=1, inplace=True)\n",
    "    stock_df.set_index('date',inplace=True, drop=False)\n",
    "    # stock_df = stock_df.asfreq(custom_BH_freq())\n",
    "    print(stock_df.index.freq)\n",
    "    display(stock_df.head())\n",
    "    \n",
    "    def load_stock_price_series(filename='IVE_bidask1min.txt', \n",
    "                                   folderpath='data/',\n",
    "                                   start_index = '2017-01-23', freq='T'):\n",
    "        import pandas as pd\n",
    "\n",
    "        # Load in the text file and set headers\n",
    "        fullfilename= folderpath+filename\n",
    "        headers = ['Date','Time','BidOpen','BidHigh','BidLow','BidClose','AskOpen','AskHigh','AskLow','AskClose']\n",
    "        stock_df = pd.read_csv(fullfilename, names=headers,parse_dates=True,usecols=['Date','Time','BidClose'])\n",
    "\n",
    "        # Create datetime index\n",
    "        date_time_index = stock_df['Date']+' '+stock_df['Time']\n",
    "        date_time_index = pd.to_datetime(date_time_index)\n",
    "        stock_df.index=date_time_index\n",
    "\n",
    "        # Select only the days after start_index\n",
    "        stock_df = stock_df[start_index:]\n",
    "\n",
    "        stock_price = stock_df['BidClose'].rename('stock_price')\n",
    "        stock_price[stock_price==0] = np.nan\n",
    "\n",
    "        return stock_price\n",
    "\n",
    "stock_price = load_stock_price_series()\n",
    "display(stock_price.head())\n",
    "\n",
    "stock_price.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELECTING A SUBSET OF STOCK_DF COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip==False:\n",
    "    stock_df = set_timeindex_freq(stock_df,verbose=0)\n",
    "    # full_df = stock_df.copy()\n",
    "    stock_df = stock_df.iloc[:,10:]\n",
    "\n",
    "    # DIsply input stock data\n",
    "    display(stock_df.head().style.set_caption('Raw Data'))\n",
    "    # plot_time_series(stock_df['price'])\n",
    "    stock_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ADDING A DELTA STOCK PRICE COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "# make new dataframe starting with date and content\n",
    "df = stock_df.copy() #'content_stopped',\n",
    "\n",
    "# create a series with all hours covering entire twitter_df\n",
    "time_index_hour_bins = pd.date_range(start = stock_df.index[0].floor('H'), end = stock_df.index[-1].ceil('H'), freq='H')#.to_period()\n",
    "\n",
    "# bin the twitter_df.index by the new time_index_hour_bins\n",
    "df['time_index_by_hour'] = pd.cut(stock_df['date'], time_index_hour_bins)\n",
    "\n",
    "# extract JUST the hour_of_day as a feature\n",
    "df['hour_of_day'] = df['date'].apply(lambda x: x.hour).apply(lambda x: dt.time(x))\n",
    "df.drop('date',axis=1,inplace=True)\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING IN TWITTER DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--------- \tHELP:\t ------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Help on function ihelp in module functions_combined_BEST:\n",
      "\n",
      "ihelp(any_function, show_help=True, show_code=True, get_source=True)\n",
      "    Call on any module or functon to display:\n",
      "    - help(any_function)\n",
      "    - source_df = inspect.getsource(any_function)\n",
      "    inspect.get)\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "--------- \tSOURCE:\t ------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "def ihelp(any_function, show_help=True, show_code=True, get_source=True): \n",
      "    \"\"\"Call on any module or functon to display:\n",
      "    - help(any_function)\n",
      "    - source_df = inspect.getsource(any_function)\n",
      "    inspect.get)\"\"\"\n",
      "    import inspect\n",
      "    import pprint as pp\n",
      "    if show_help:\n",
      "        \n",
      "        print(\"---\"*40)\n",
      "        print(\"---\"*3,'\\tHELP:\\t',\"---\"*30)\n",
      "        print(\"---\"*40)\n",
      "        help(any_function)\n",
      "#         print('\\n\\n',\"---\"*20,'\\n')\n",
      "        \n",
      "    if show_code or get_source:\n",
      "        \n",
      "        import inspect\n",
      "        source_DF = inspect.getsource(any_function)\n",
      "        print(\"---\"*40)\n",
      "        print(\"---\"*3,'\\tSOURCE:\\t',\"---\"*30)\n",
      "        print(\"---\"*40)\n",
      "        print(source_DF)    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from functions_combined_BEST import ihelp, load_twitter_df, df_column_report, make_half_hour_range\n",
    "ihelp(ihelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     2,
     30,
     73,
     101
    ]
   },
   "outputs": [],
   "source": [
    "if skip==False:\n",
    "    import inspect\n",
    "    def ihelp(any_function, show_help=True, show_code=True, get_source=True): \n",
    "        \"\"\"Call on any module or functon to display:\n",
    "        - help(any_function)\n",
    "        - source_df = inspect.getsource(any_function)\n",
    "        inspect.get)\"\"\"\n",
    "        import inspect\n",
    "        import pprint as pp\n",
    "        if show_help:\n",
    "\n",
    "            print(\"---\"*40)\n",
    "            print(\"---\"*3,'\\tHELP:\\t',\"---\"*30)\n",
    "            print(\"---\"*40)\n",
    "            help(any_function)\n",
    "    #         print('\\n\\n',\"---\"*20,'\\n')\n",
    "\n",
    "        if show_code or get_source:\n",
    "\n",
    "            import inspect\n",
    "            source_DF = inspect.getsource(any_function)\n",
    "            print(\"---\"*40)\n",
    "            print(\"---\"*3,'\\tSOURCE:\\t',\"---\"*30)\n",
    "            print(\"---\"*40)\n",
    "            print(source_DF)    \n",
    "\n",
    "\n",
    "    #***#\n",
    "    # del(twitter_df)\n",
    "\n",
    "    def load_twitter_df(overwrite=True,set_index='time_index',verbose=2,replace_na=''):\n",
    "\n",
    "        try: twitter_df\n",
    "        except NameError: twitter_df = None\n",
    "        if twitter_df is not None:\n",
    "            print('twitter_df already exists.')\n",
    "            if overwrite==True:\n",
    "                print('Overwrite=True. deleting original...')\n",
    "                del(twitter_df)\n",
    "\n",
    "        if twitter_df is None:\n",
    "            print('loading twitter_df')\n",
    "\n",
    "            twitter_df = pd.read_csv('data/trump_twitter_archive_df.csv', encoding='utf-8', parse_dates=True)\n",
    "            twitter_df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "            twitter_df['date']  = pd.to_datetime(twitter_df['date'])\n",
    "            twitter_df['time_index'] = twitter_df['date'].copy()\n",
    "            twitter_df.set_index(set_index,inplace=True,drop=True)\n",
    "\n",
    "\n",
    "            # Fill in missing values before merging with stock data\n",
    "            twitter_df.fillna(replace_na, inplace=True)\n",
    "            twitter_df.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "            # RECASTING A COUPLE COLUMNS\n",
    "            twitter_df['is_retweet'] = twitter_df['is_retweet'].astype('bool')\n",
    "            twitter_df['id_str'] = twitter_df['id_str'].astype('str')\n",
    "            twitter_df['sentiment_class'] = twitter_df['sentiment_class'].astype('category')\n",
    "\n",
    "    #         twitter_df.reset_index(inplace=True)\n",
    "            # Check header and daterange of index\n",
    "        if verbose>0:\n",
    "            display(twitter_df.head(2))\n",
    "            print(twitter_df.index[[0,-1]])\n",
    "        return twitter_df\n",
    "\n",
    "\n",
    "    # twitter_df = load_twitter_df()\n",
    "\n",
    "    #***#\n",
    "    # DISPLAYING PLAN FOR DEALING WITH DATA\n",
    "    # df_dtypes =pd.DataFrame({'type':twitter_df.dtypes})#,'null':twitter_df.isna().sum(),'count':twitter_df.count()})\n",
    "    def df_column_report(twitter_df, sort_column=None, ascending=True, interactive=True):\n",
    "        from ipywidgets import interact\n",
    "        df_dtypes=pd.DataFrame()\n",
    "        df_dtypes = pd.DataFrame({'Column #': range(len(twitter_df.columns)),'Column Name':twitter_df.columns,\n",
    "                                  'Data Types':twitter_df.dtypes.astype('str')}).set_index('Column Name') #.set_index('Column Name')\n",
    "\n",
    "        decision_map = {'object':'join','int64':'sum','bool':'to_list()?','float64':'drop and recalculate'}\n",
    "\n",
    "        df_dtypes['action'] = df_dtypes['Data Types'].map(decision_map)#column_list\n",
    "    #     df_dtypes.style.set_caption('DF Columns, Dtypes, and Course of Action')\n",
    "\n",
    "        if sort_column is not None:\n",
    "            df_dtypes.sort_values(by =sort_column,ascending=ascending, axis=0, inplace=True)\n",
    "        if interactive==False:\n",
    "            return df_dtypes\n",
    "        else: \n",
    "\n",
    "            @interact(column= df_dtypes.columns,direction={'ascending':True,'descending':False})\n",
    "            def sort_df(column, direction):\n",
    "                return df_dtypes.sort_values(by=column,axis=0,ascending=direction)\n",
    "\n",
    "    # df_dtypes =  df_column_report(twitter_df, sort_column=['Data Types','Column #'])\n",
    "    # df_dtypes\n",
    "    # res_df = df_column_report(twitter_df)\n",
    "\n",
    "    #***#a\n",
    "    # twitter_df = load_twitter_df()\n",
    "\n",
    "    def make_half_hour_range(twitter_df):\n",
    "\n",
    "        # Get timebin before the first timestamp that starts at 30m into the hour\n",
    "        ofst_30m_early=pd.offsets.Minute(-30)\n",
    "        start_idx = ofst_30m_early(twitter_df['date'].iloc[0].floor('H'))\n",
    "\n",
    "        # Get timbin after last timestamp that starts 30m into the hour.\n",
    "        ofst_30m_late =pd.offsets.Minute(30)\n",
    "        end_idx= ofst_30m_late(twitter_df['date'].iloc[-1].ceil('H'))\n",
    "\n",
    "\n",
    "        # Make time bins using the above start and end points \n",
    "        half_hour_range = pd.date_range(start =start_idx, end = end_idx, freq='30T')#.to_period()\n",
    "        half_hour_intervals = pd.interval_range(start=start_idx, end=end_idx,freq='30T',name='half_hour_bins',closed='left')\n",
    "\n",
    "        return half_hour_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to merge stock-market-business hours tweets?\n",
    "- use `custom_BH_freq` to create a new column that attempts to re-cast the index as this frequency.\n",
    "    - separate the index off first to another column/dataframe.\n",
    "    - create a second column that rounds/floors/ceils the timestamp values to the correct business hour\n",
    "    - **NOTE**: -filling? revisit\n",
    "    \n",
    "- Fundamental question: how do I want to determine which stock timebin to evaluate effect of Trump tweet?\n",
    "    - time series analysis would want the tweet to be in the hour PRIOR to the timepoint to be judged.\n",
    "- **SO how to best accomplish this?**\n",
    "    - if do `twitter_df['date'].floor(H), then any tweets from within an hour would be classified as that hour's timebin,\n",
    "        - if he tweeted at 12:55, that would be considered 12 pm, so using 1 pm as the +1 hour timebin is only really 5 MINS!\n",
    "        - What if add +1hour to the `date` column's timestamps, then use `.round('H')`\n",
    "            - **This would probably be the best way to go about it!**\n",
    "            \n",
    "**TO DO:**\n",
    "- [ ] Add +1 hour to twitter_df['date'], then use .round('H')\n",
    "\n",
    "- **SIMPLER APPROACH: Write function to concatenate rows** (07/04/19)\n",
    "    - use new_df = df.resample('H').apply(my_func) \n",
    "         (or can I do 30mins instead of 'H'?)\n",
    "         \n",
    "## HOW TO INSTRUCTIONS FOR FUNCTIONS BELOW\n",
    "\n",
    "```python \n",
    "\n",
    "# #***#  \n",
    "twitter_df = load_twitter_df()\n",
    "\n",
    "half_hour_intervals = make_half_hour_range(twitter_df)\n",
    "\n",
    "twitter_df, bin_codes = bin_df_by_date_intervals(twitter_df, half_hour_intervals)\n",
    "\n",
    "group_indices = twitter_df.groupby('int_bins').groups\n",
    "group_indices = [(k,v) for k,v in group_indices.items()]\n",
    "\n",
    "\n",
    "#***#\n",
    "new_col_order = ['date','left_edge','content_raw','content_stopped','tokens_stopped',\n",
    "                  'retweet_count','favorite_count','case_ratio','sentiment_scores','compound_score','int_bins']\n",
    "\n",
    "twitter_grouped = collapse_df_by_group_indices(twitter_df, group_indices, new_col_order=new_col_order)\n",
    "# twitter_grouped.head(2)\n",
    "\n",
    "twitter_grouped['time_bin'] = twitter_grouped['left_edge'].apply(lambda x: pd.to_datetime(x[0]))\n",
    "twitter_grouped.set_index('time_bin',drop=True, inplace=True)\n",
    "twitter_grouped.head(2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Actions by Columns Types\n",
    "\n",
    "- string/object columns (twitter_df.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TAKING A SMALLER TWITTER_DF \n",
    "# twitter_df = twitter_df.iloc[:1000,:]\n",
    "# display(twitter_df.head())\n",
    "# type_list = twitter_df.dtypes\n",
    "# # display(type_list)\n",
    "# # display(twitter_df.index)\n",
    "# # twitter_df.set_index('time_index',inplace=True, verify_integrity=True)\n",
    "# # twitter_df.duplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get timebin before the first timestamp that starts at 30m into the hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def cut_df_by_intervals_to_number_code, concat_df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_combined_BEST import int_to_ts, bin_df_by_date_intervals, concatenate_group_data, collapse_df_by_group_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0,
     2,
     27,
     59,
     100
    ]
   },
   "outputs": [],
   "source": [
    "if skip==False:\n",
    "    #***#\n",
    "    def int_to_ts(int_list, as_datetime=False, as_str=True):\n",
    "        \"\"\"Accepts one Panda's interval and returns the left and right ends as either strings or Timestamps.\"\"\"\n",
    "        if as_datetime & as_str:\n",
    "            raise Exception('Only one of `as_datetime`, or `as_str` can be True.')\n",
    "\n",
    "        left_edges =[]\n",
    "        right_edges= []\n",
    "\n",
    "        for interval in int_list:\n",
    "            int_str = interval.__str__()[1:-1]\n",
    "            left,right = int_str.split(',')\n",
    "            left_edges.append(left)\n",
    "            right_edges.append(right)\n",
    "\n",
    "\n",
    "        if as_str:\n",
    "            return left_edges, right_edges\n",
    "\n",
    "        elif as_datetime:\n",
    "            left = pd.to_datetime(left)\n",
    "            right = pd.to_datetime(right)\n",
    "            return left,right\n",
    "\n",
    "\n",
    "    # Step 1:     \n",
    "    def bin_df_by_date_intervals(test_df,half_hour_intervals,column='date'):\n",
    "        \"\"\"\"\"\"\n",
    "        # Cut The Date column into interval bins, \n",
    "        cut_date = pd.cut(test_df[column], bins=half_hour_intervals)#,labels=list(range(len(half_hour_intervals))), retbins=True)\n",
    "        test_df['int_times'] = cut_date    \n",
    "\n",
    "        # convert to str to be used as group names/codes\n",
    "        unique_bins = cut_date.astype('str').unique()\n",
    "        num_code = list(range(len(unique_bins)))\n",
    "\n",
    "        # Dictioanry of number codes to be used for interval groups\n",
    "        bin_codes = dict(zip(num_code,unique_bins))#.astype('str')\n",
    "\n",
    "\n",
    "        # Mapper dictionary to convert intervals into number codes\n",
    "        bin_codes_mapper = {v:k for k,v in bin_codes.items()}\n",
    "\n",
    "\n",
    "        # Add column to the dataframe, then map integer code onto it\n",
    "        test_df['int_bins'] = test_df['int_times'].astype('str').map(bin_codes_mapper)\n",
    "\n",
    "\n",
    "        # Get the left edge of the bins to use later as index (after grouped)\n",
    "        left_out, _ =int_to_ts(test_df['int_times'])#.apply(lambda x: int_to_ts(x))    \n",
    "        test_df['left_edge'] = pd.to_datetime(left_out)\n",
    "\n",
    "        # bin codes to labels \n",
    "        bin_codes = [(k,v) for k,v in bin_codes.items()]\n",
    "\n",
    "        return test_df, bin_codes\n",
    "\n",
    "\n",
    "    def concatenate_group_data(group_df_or_series):\n",
    "        \"\"\"Accepts a series or dataframe from a groupby.get_group() loop.\n",
    "        Adds TweetFreq column for # of rows concatenate. If input is series, \n",
    "        TweetFreq=1 and series is returned.\"\"\"\n",
    "\n",
    "        import pandas as pd\n",
    "        from pandas.api import types as tp\n",
    "\n",
    "        if isinstance(group_df_or_series, pd.Series):\n",
    "\n",
    "            group_data = group_df_or_series\n",
    "\n",
    "    #         group_data.index = group_df_or_series.index\n",
    "            group_data['TweetFreq'] = 1\n",
    "\n",
    "            return group_data\n",
    "\n",
    "        # if the group is a dataframe:\n",
    "        elif isinstance(group_df_or_series, pd.DataFrame):\n",
    "\n",
    "            df = group_df_or_series\n",
    "\n",
    "            # create an output series to collect combined data\n",
    "            group_data = pd.Series(index=df.columns)\n",
    "            group_data['TweetFreq'] = df.shape[0]\n",
    "\n",
    "\n",
    "            for col in df.columns:\n",
    "\n",
    "                combined=[]\n",
    "                col_data = []\n",
    "\n",
    "                col_data = df[col]\n",
    "                combined=col_data.values\n",
    "\n",
    "                group_data[col] = combined\n",
    "\n",
    "        return group_data\n",
    "\n",
    "\n",
    "    #***#\n",
    "    def collapse_df_by_group_indices(twitter_df,group_indices, new_col_order=None):\n",
    "        \"\"\"Loops through the group_indices provided to concatenate each group into\n",
    "        a single row and combine into one dataframe with the ______ as the index\"\"\"\n",
    "\n",
    "\n",
    "        # Create a Panel to temporarily hold the group series and dataframes\n",
    "        # group_dict_to_df = {}\n",
    "        # create a dataframe with same columns as twitter_df, and index=group ids from twitter_groups\n",
    "        group_df_index = [x[0] for x in group_indices]\n",
    "\n",
    "\n",
    "        twitter_grouped = pd.DataFrame(columns=twitter_df.columns, index=group_df_index)\n",
    "        twitter_grouped['TweetFreq'] =0\n",
    "\n",
    "        for (idx,group_members) in group_indices:\n",
    "\n",
    "            group_df = twitter_df.loc[group_members]\n",
    "\n",
    "            combined_series = concatenate_group_data(group_df)\n",
    "\n",
    "    #         twitter_grouped.loc[idx,:] = combined_series\n",
    "            twitter_grouped.loc[idx] = combined_series#.values\n",
    "\n",
    "        if new_col_order==None:\n",
    "            return twitter_grouped\n",
    "\n",
    "        else:\n",
    "            df_out = twitter_grouped[new_col_order].copy()\n",
    "            df_out.index = group_df_index#twitter_grouped.index\n",
    "            return df_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that twitter df has int_bins, use them for groupby and concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect.getsourcelines(load_twitter_df)\n",
    "# twitter_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### TROUBLESHOOTING CODE BELOW\n",
    "# twitter_df = load_twitter_df()\n",
    "\n",
    "# half_hour_intervals = make_half_hour_range(twitter_df)\n",
    "\n",
    "# cut_date = pd.cut(twitter_df['date'], bins=half_hour_intervals)#,labels=list(range(len(half_hour_intervals))), retbins=True)\n",
    "# twitter_df['int_times'] =cut_date\n",
    "# # display(twitter_df.head())\n",
    "\n",
    "\n",
    "# # convert to str to be used as group names/codes\n",
    "# unique_bins = cut_date.astype('str').unique()\n",
    "# num_code = list(range(len(unique_bins)))\n",
    "\n",
    "# # Dictioanry of number codes to be used for interval groups\n",
    "# bin_codes = dict(zip(num_code,unique_bins))#.astype('str')\n",
    "\n",
    "\n",
    "# # Mapper dictionary to convert intervals into number codes\n",
    "# bin_codes_mapper = {v:k for k,v in bin_codes.items()}\n",
    "\n",
    "\n",
    "# # Add column to the dataframe, then map integer code onto it\n",
    "# twitter_df['int_bins'] = twitter_df['int_times'].astype('str').map(bin_codes_mapper)\n",
    "# twitter_df.head()\n",
    "\n",
    "# # Get the left edge of the bins to use later as index (after grouped)\n",
    "# left_out, _ =int_to_ts(twitter_df['int_times'])#.apply(lambda x: int_to_ts(x))    \n",
    "# twitter_df['left_edge'] = pd.to_datetime(left_out)\n",
    "\n",
    "# # bin codes to labels \n",
    "# bin_codes = [(k,v) for k,v in bin_codes.items()]\n",
    "\n",
    "\n",
    "# group_indices = twitter_df.groupby('int_bins').groups\n",
    "# group_indices = [(k,v) for k,v in group_indices.items()]\n",
    "\n",
    "\n",
    "# #***#\n",
    "# new_col_order = ['date','left_edge','content_raw','content_stopped','tokens_stopped',\n",
    "#                   'retweet_count','favorite_count','case_ratio','sentiment_scores','compound_score','int_bins']\n",
    "\n",
    "# twitter_grouped = collapse_df_by_group_indices(twitter_df, group_indices, new_col_order=new_col_order)\n",
    "\n",
    "# twitter_grouped['time_bin'] = twitter_grouped['left_edge'].apply(lambda x: pd.to_datetime(x[0]))\n",
    "# twitter_grouped.set_index('time_bin',drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if skip==False:\n",
    "    # #***#  \n",
    "    twitter_df = load_twitter_df()\n",
    "\n",
    "    half_hour_intervals = make_half_hour_range(twitter_df)\n",
    "\n",
    "    twitter_df, bin_codes = bin_df_by_date_intervals(twitter_df, half_hour_intervals)\n",
    "\n",
    "    group_indices = twitter_df.groupby('int_bins').groups\n",
    "    group_indices = [(k,v) for k,v in group_indices.items()]\n",
    "\n",
    "\n",
    "    #***#\n",
    "    new_col_order = ['date','left_edge','content_raw','content_stopped','tokens_stopped',\n",
    "                      'retweet_count','favorite_count','case_ratio','sentiment_scores','compound_score','int_bins']\n",
    "\n",
    "    twitter_grouped = collapse_df_by_group_indices(twitter_df, group_indices, new_col_order=new_col_order)\n",
    "    # twitter_grouped.head(2)\n",
    "\n",
    "    twitter_grouped['time_bin'] = twitter_grouped['left_edge'].apply(lambda x: pd.to_datetime(x[0]))\n",
    "    twitter_grouped.set_index('time_bin',drop=True, inplace=True)\n",
    "    twitter_grouped.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTERACTIVE PLOT TIME SERIES\n",
    "\n",
    "- Make a verison of plot_time_series using some version of interact to be able to ADJUST THE TIME AXIS\n",
    "\n",
    "- https://github.com/bloomberg/bqplot/issues/712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if skip==False:\n",
    "    # Make a Layout with the range slider and labels as two different boxes, one on top of the other\n",
    "\n",
    "    start_date = stock_df.index[0]\n",
    "    end_date  = stock_df.index[-1]\n",
    "\n",
    "    def make_date_range_slider(start_date,end_date,freq='D'):\n",
    "\n",
    "        from ipywidgets import interact, interactive, interaction, Label, Box, Layout\n",
    "        import ipywidgets as iw\n",
    "        from datetime import datetime\n",
    "\n",
    "        # specify the date range from user input\n",
    "        dates = pd.date_range(start_date, end_date,freq=freq)\n",
    "\n",
    "        # specify formatting based on frequency code\n",
    "        date_format_lib={'D':'%m/%d/%Y','H':'%m/%d/%Y: %T'}\n",
    "        freq_format = date_format_lib[freq]\n",
    "\n",
    "\n",
    "        # creat options list and index for SelectionRangeSlider\n",
    "        options = [(date.strftime(date_format_lib[freq]),date) for date in dates]\n",
    "        index = (0, len(options)-1)\n",
    "\n",
    "        #     # Create out function to display outputs (not needed?)\n",
    "        #     out = iw.Output(layout={'border': '1px solid black'})\n",
    "        #     #     @out.capture()\n",
    "\n",
    "        # Instantiate the date_range_slider\n",
    "        date_range_slider = iw.SelectionRangeSlider(\n",
    "            options=options, index=index, description = 'Date Range',\n",
    "            orientation = 'horizontal',layout={'width':'500px','grid_area':'main'},#layout=Layout(grid_area='main'),\n",
    "            readout=True)\n",
    "\n",
    "        # Save the labels for the date_range_slider as separate items\n",
    "        date_list = [date_range_slider.label[0], date_range_slider.label[-1]]\n",
    "        date_label = iw.Label(f'{date_list[0]} -- {date_list[1]}',\n",
    "                             layout=Layout(grid_area='header'))\n",
    "\n",
    "        def updateXAxis(change):\n",
    "            #Update X-axis min/max value here\n",
    "            if change['type'] == 'change' and change['name'] == 'value':\n",
    "                x_start = change['new'][0]\n",
    "                x_end = change['new'][1]\n",
    "        date_range_slider.observe(updateXAxis)\n",
    "    #             x_sc.min = change['new'][0]\n",
    "    #             x_sc.max = change['new'][1]\n",
    "\n",
    "    #     source1, target1 = date_range_slider, date_label\n",
    "    #     dl = iw.dlink((soruce1,'label'),(target1,'value'))\n",
    "\n",
    "    #     ## ADJUST LABEL OUTPUT TO MATCH SLIDER\n",
    "    #     output2 = date_label#widgets.Output()\n",
    "    #     def on_value_change(change):\n",
    "    #         with output2:\n",
    "    #             print(change['new'])\n",
    "    #     header  = date_range_slider\n",
    "    #     main    = date_label      \n",
    "\n",
    "    #     slider_items=[date_range_slider, date_label]\n",
    "    #     output = iw.GridBox(children=[date_range_slider,date_label],\n",
    "    #                        layout=Layout(\n",
    "    #                        grid_template_rows='auto auto',\n",
    "    #                        grid_template_columns='auto auto',\n",
    "    #                        grid_template_areas='''\n",
    "    #                        \"header header\"\n",
    "    #                        \"main main\"\n",
    "    #                        '''))# display='flex','flex_flow'\n",
    "        return date_range_slider\n",
    "\n",
    "    make_date_range_slider(start_date, end_date,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Instantiate the date_range_slider\n",
    "# date_range_slider = iw.SelectionRangeSlider(\n",
    "#     options=options, index=index, description = 'Date Range',\n",
    "#     orientation = 'horizontal',layout={'width':'500px'},readout=False)\n",
    "\n",
    "# # Save the labels for the date_range_slider as separate items\n",
    "# # date_list = [date_range_slider.label[0], date_range_slider.label[-1]]\n",
    "# date_label1 = iw.Label(date_range_slider.label[0])\n",
    "# date_label2 = iw.Label(date_range_slider.label[-1])\n",
    "# source_1, target_1 = date_range_slider, iw.Label\n",
    "\n",
    "# def tf_label(label):\n",
    "#     return str(label[0])\n",
    "# dl1 = iw.dlink((source_1,'label',lambda x: tf_label(x)),(target_1,'value'))#,lambda x: str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE AND LOAD GROUPED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_grouped.to_csv('twitter_data_grouped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_grouped.loc['02-21-2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df.loc['02-21-2017'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_grouped.loc['02-21-2017':].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_prices = stock_df['price']\n",
    "# stock_prices.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBH = custom_BH_freq()\n",
    "\n",
    "# grouped_resampled = twitter_grouped.loc['02-21-2017':].asfreq(CBH)\n",
    "# stock_resampled = stock_df.loc['02-21-2017':].asfreq(CBH)\n",
    "# # grouped_resampled = grouped_resampled.loc[stock_df.index[0]:stock_df.index[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_range = stock_resampled.index\n",
    "# display_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_twitter_valid = grouped_resampled['content_raw'].notnull().index\n",
    "# grouped_twitter_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # display_range = grouped_resampled.index\n",
    "# from ipywidgets import interact\n",
    "# display_range = grouped_resampled['content_raw'].notnull().index\n",
    "\n",
    "\n",
    "# @interact(date=display_range, num_items=range(3,10))\n",
    "# def display_date(date=['02-22-2017'], num_items=10, filter_null=True):\n",
    "    \n",
    "#     display(grouped_resampled.loc[date:].head(num_items).style.set_caption('Twitter'))\n",
    "#     display(stock_resampled.loc[date:].head(num_items).style.set_caption('S&P500'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_resampled['join_date'] = grouped_resampled.index\n",
    "# stock_df['join_date'] =  stock_df.index\n",
    "\n",
    "# print(grouped_resampled.join_date)\n",
    "# print(stock_df.join_date)\n",
    "\n",
    "# # print(len(grouped_resampled),len(twitter_grouped))\n",
    "\n",
    "# # compare_indices = [True for i in grouped_resampled.index if i in stock_df.index]\n",
    "# # np.sum(compare_indices==False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOKMARK _ NEW APPROACH. \n",
    "\n",
    "- use `load_stock_price_series()` to get a SERIES of just stock prices (not yet on official Freq)\n",
    "- use twitter_df data (not grouped)\n",
    "- use new function to take each tweet's timestamp, then find the corresponding stock price X amount of time later (then difference)\n",
    "\n",
    "### GOAL NOW:\n",
    "\n",
    "- [ ] write a function that will tweet timestamps and find the next corresponding stock price to use as labels\n",
    "- [ ] **add a rolling forward offset that would move off hours timestamps to 09:30 am next day**\n",
    "\n",
    "`match_stock_price_to_tweets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_resampled.index, stock_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_resampled = grouped_resampled.join(stock_df['price'],how='right')#,left_index=True, right_index=True)\n",
    "# display(grouped_resampled.head())\n",
    "# display(grouped_resampled.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## LOAD STOCK PRICE SERIES\n",
    "# # Make stock price reference series with minute resolution\n",
    "# stock_price = load_stock_price_series()\n",
    "# print(f'Null Values when Freq={stock_price.index.freq}:\\t{stock_price.isna().sum()}')\n",
    "\n",
    "# # Change to Minute-Data\n",
    "# stock_price = stock_price.asfreq('T')\n",
    "# print(f'Null Values when Freq={stock_price.index.freq}:\\t{stock_price.isna().sum()}')\n",
    "\n",
    "# stock_price.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dropna in stock_Series?\n",
    "# # stock_price.fillna(-999, inplace=True)\n",
    "# stock_price.dropna(inplace=True)\n",
    "# stock_price.index\n",
    "# # stock_price.loc[stock_price > 0].plot()\n",
    "# # plt.figure()\n",
    "# # stock_price.loc[stock_price < 0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IN STOCK PRICE SERIES\n",
    "# try \n",
    "# display(stock_price.head())\n",
    "# stock_price.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# test_per = twitter_periods.index[0]\n",
    "# test_per\n",
    "\n",
    "# test_index = twitter_df.index[0]\n",
    "# test_index\n",
    "\n",
    "# # get_month_day_year(test_per), get_month_day_year(test_index)\n",
    "# test_index.second\n",
    "\n",
    "# twitter_df['B_day']= [str(x.strftime('%m-%d-%Y')) for x in twitter_periods['time_index'].values]\n",
    "\n",
    "# twitter_df['B_day'][0],twitter_df['day'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CURRENT:\n",
    "code as of morning of 07/08\n",
    "```python\n",
    "\n",
    "# CREATE COLUMNS TO GET NEXT BUSINESS DAY\n",
    "def get_month_day_year(x):\n",
    "    x_date =dt.date(month=x.month, day=x.day, year=x.year)\n",
    "    return x_date.strftime('%m-%d-%Y')\n",
    "\n",
    "def get_time_of_day(x):\n",
    "    x_time = dt.time(hour= x.hour, minute=x.minute, second=x.second)\n",
    "    return x_time.strftime('%T')\n",
    "\n",
    "\n",
    "# Separate day and time for twitter timestamp \n",
    "twitter_df['day'] = twitter_df['date'].apply(lambda x: get_month_day_year(x))\n",
    "# twitter_df['day'] =  pd.to_datetime(twitter_df['day'])\n",
    "\n",
    "twitter_df['time'] =  twitter_df['date'].apply(lambda x: get_time_of_day(x))\n",
    "\n",
    "# Get the corresponding next business day for each row\n",
    "twitter_periods = twitter_df.to_period('B')\n",
    "twitter_periods.reset_index(inplace=True)\n",
    "\n",
    "# def get_bday_btime(x):\n",
    "#     for r\n",
    "twitter_df['B_day']= [str(x.strftime('%m-%d-%Y')) for x in twitter_periods['time_index'].values]\n",
    "twitter_df['B_shifted']=np.where(twitter_df['day']== twitter_df['B_day'],False,True);\n",
    "twitter_df['B_time'] = np.where(twitter_df['day']== twitter_df['B_day'],twitter_df['time'],dt.time(hour=9, minute=30))#:30:00');\n",
    "twitter_df['B_dt_index'] = [ str(twitter_df['B_day'].iloc[x]) +'  '+ str(twitter_df['B_time'].iloc[x])  for x in range(len(twitter_df))]\n",
    "twitter_df['B_dt_index'] = pd.to_datetime(twitter_df['B_dt_index'])#asfreq('T')\n",
    "# twitter_df['B_dt_index'] = twitter_df['B_dt_index'].round('T')\n",
    "\n",
    "\n",
    "\n",
    "twitter_df.head(16)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(twitter_df['time'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts = twitter_df.index[2]\n",
    "# print(ts)\n",
    "# ts.strftime('%H:%M')\n",
    "# ts.round('T')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL WORKFLOW FOR TWITTER-STOCK DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_combined_BEST import get_B_day_time_index_shift, reorder_twitter_df_columns, match_stock_price_to_tweets, unpack_match_stocks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def functions for getting business day info (get_B_day_time_index_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "if skip==False:\n",
    "    def get_B_day_time_index_shift(test_df, verbose=1):\n",
    "\n",
    "        fmtYMD= '%Y-%m-%d'\n",
    "\n",
    "        test_df['day']= test_df['date'].dt.strftime('%Y-%m-%d')\n",
    "        test_df['time'] = test_df['date'].dt.strftime('%T')\n",
    "        test_df['dayofweek'] = test_df['date'].dt.day_name()\n",
    "\n",
    "        test_df_to_period = test_df[['date','content']]\n",
    "        test_df_to_period = test_df_to_period.to_period('B')\n",
    "        test_df_to_period['B_periods'] = test_df_to_period.index.values\n",
    "        test_df_to_period['B_day'] = test_df_to_period['B_periods'].apply(lambda x: x.strftime(fmtYMD))\n",
    "\n",
    "\n",
    "\n",
    "        test_df['B_day'] = test_df_to_period['B_day'].values\n",
    "        test_df['B_shifted']=np.where(test_df['day']== test_df['B_day'],False,True)\n",
    "        test_df['B_time'] = np.where(test_df['B_shifted'] == True,'09:30:00', test_df['time'])\n",
    "\n",
    "        test_df['B_dt_index'] = pd.to_datetime(test_df['B_day'] + ' ' + test_df['B_time']) \n",
    "\n",
    "        test_df['time_shift'] = test_df['B_dt_index']-test_df['date'] \n",
    "\n",
    "        if verbose > 0:\n",
    "            test_df.head(20)\n",
    "\n",
    "        return test_df\n",
    "\n",
    "    def reorder_twitter_df_columns(twitter_df, order=[]):\n",
    "        if len(order)==0:\n",
    "            order=['date','dayofweek','B_dt_index','source','content','content_raw','retweet_count','favorite_count','sentiment_scores','time_shift']\n",
    "        twitter_df_out = twitter_df[order]\n",
    "        twitter_df_out.index = twitter_df.index\n",
    "        return twitter_df_out\n",
    "\n",
    "\n",
    "    def match_stock_price_to_tweets(tweet_timestamp,time_after_tweet= 30,time_freq ='T',stock_price=[]):#stock_price_index=stock_date_data):\n",
    "\n",
    "        import pandas as pd\n",
    "        from datetime import datetime as dt\n",
    "        # output={'pre_tweet_price': price_at_tweet,'post_tweet_price':price_after_tweet,'delta_price':delta_price, 'delta_time':delta_time}\n",
    "        output={}\n",
    "        # convert tweet timestamp to minute accuracy\n",
    "        ts=[]\n",
    "        ts = pd.to_datetime(tweet_timestamp).round(time_freq)\n",
    "\n",
    "        BH = pd.tseries.offsets.BusinessHour(start='09:30',end='16:30')\n",
    "        BD = pd.tseries.offsets.BusinessDay()\n",
    "\n",
    "\n",
    "        # checking if time is within stock_date_data\n",
    "    #     def roll_B_day_forward(ts):\n",
    "\n",
    "        if ts not in stock_price.index:\n",
    "            ts = BH.rollforward(ts)        \n",
    "\n",
    "            if ts not in stock_price.index:\n",
    "                return np.nan#\"ts2_not_in_index\"\n",
    "\n",
    "        # Get price at tweet time\n",
    "        price_at_tweet = stock_price.loc[ts]\n",
    "\n",
    "        if np.isnan(price_at_tweet):\n",
    "            output['pre_tweet_price'] = np.nan\n",
    "        else: \n",
    "            output['pre_tweet_price'] = price_at_tweet\n",
    "\n",
    "\n",
    "        # Use timedelta to get desired timepoint following tweet\n",
    "        hour_freqs = 'BH','H','CBH'\n",
    "        day_freqs = 'B','D'\n",
    "\n",
    "        if time_freq=='T':\n",
    "            ofst=pd.offsets.Minute(time_after_tweet)\n",
    "\n",
    "        elif time_freq in hour_freqs:\n",
    "            ofst=pd.offsets.Hour(time_after_tweet)\n",
    "\n",
    "        elif time_freq in day_freqs:\n",
    "            ofst=pd.offsets.Day(time_after_tweet)\n",
    "\n",
    "\n",
    "        # get timestamp to check post-tweet price\n",
    "        post_tweet_ts = ofst(ts)\n",
    "\n",
    "\n",
    "        if post_tweet_ts not in stock_price.index:\n",
    "    #         post_tweet_ts =BD.rollforward(post_tweet_ts)\n",
    "            post_tweet_ts = BH.rollforward(post_tweet_ts)\n",
    "\n",
    "            if post_tweet_ts not in stock_price.index:\n",
    "                return np.nan\n",
    "\n",
    "\n",
    "        # Get next available stock price\n",
    "        price_after_tweet = stock_price.loc[post_tweet_ts]\n",
    "        if np.isnan(price_after_tweet):\n",
    "            output['post_tweet_price'] = 'NaN in stock_price'\n",
    "        else:\n",
    "            # calculate change in price\n",
    "            delta_price = price_after_tweet - price_at_tweet\n",
    "            delta_time = post_tweet_ts - ts\n",
    "            output['post_tweet_price'] = price_after_tweet\n",
    "            output['delta_time'] = delta_time\n",
    "            output['delta_price'] = delta_price\n",
    "\n",
    "    #         output={'pre_tweet_price': price_at_tweet,'post_tweet_price':price_after_tweet,'delta_price':delta_price, 'delta_time':delta_time}\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def unpack_match_stocks(stock_dict):\n",
    "        stock_series = pd.Series(stock_dict)\n",
    "        return stock_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###   APPLYING FULL WORKFLOW WRITTEN ABOVE IN CODE ###\n",
    "# ## LOAD IN STOCK PRICE\n",
    "# del stock_price\n",
    "# try: stock_price\n",
    "# except NameError: stock_price = None\n",
    "# if stock_price is  None:    \n",
    "#     print('loading stock_price')\n",
    "#     stock_price = load_stock_price_series()\n",
    "# else:\n",
    "#     print('using pre-existing stock_price')\n",
    "        \n",
    "# # Make sure stock_price is loaded as minute data\n",
    "# stock_price = stock_price.asfreq('T')\n",
    "# stock_price.isna().sum()\n",
    "# # stock_price.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_price[:10]\n",
    "# stock_times = stock_price.index.strftime('%T')\n",
    "# stock_days = stock_price.index.day_name() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_details = pd.concat([stock_price, pd.Series(stock_times.values), pd.Series(stock_days.values)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### INVESTINGATING STOCK PRICE MISSING DATAA @NOW-ish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_details = pd.DataFrame({'times':stock_times,'days': stock_days})\n",
    "# stock_details = pd.concat([stock_price.reset_index(),stock_details],axis=1)\n",
    "# stock_details.set_index('index',inplace=True)\n",
    "# display(stock_details.head())\n",
    "# stock_details.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_details.loc[stock_details['stock_price'].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport\n",
    "# ProfileReport(twitter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR NOW - GOING FORWARD WITH 4000 TWEETS WITH PRICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_combined_BEST import load_raw_twitter_file, full_twitter_df_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#### NOW ALL AS FUNCTIONS BELOW\n",
    "\n",
    "\n",
    "# ###   APPLYING FULL WORKFLOW WRITTEN ABOVE IN CODE ###\n",
    "# ## LOAD IN STOCK PRICE\n",
    "# # del stock_price\n",
    "# try: stock_price\n",
    "# except NameError: stock_price = None\n",
    "# if stock_price is  None:    \n",
    "#     print('loading stock_price')\n",
    "#     stock_price = load_stock_price_series()\n",
    "# else:\n",
    "#     print('using pre-existing stock_price')\n",
    "        \n",
    "# # Make sure stock_price is loaded as minute data\n",
    "# stock_price = stock_price.asfreq('T')\n",
    "# stock_price.dropna(inplace=True)\n",
    "\n",
    "# ## LOAD TWEETS, SELECT THE PROPER DATE RANGE AND COLUMNS\n",
    "# twitter_df = load_twitter_df(verbose=0)\n",
    "# twitter_df = twitter_df.loc[stock_price.index[0]:stock_price.index[-1]]\n",
    "      \n",
    "      \n",
    "# twitter_df = twitter_df[['date','source','content','content_raw','retweet_count','favorite_count','sentiment_scores']]\n",
    "# # twitter_df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Get get the business day index to account for tweets during off-hours\n",
    "# twitter_df = get_B_day_time_index_shift(twitter_df,verbose=1)\n",
    "\n",
    "# # Reorder Columns to desired order\n",
    "# twitter_df = reorder_twitter_df_columns(twitter_df,\n",
    "#                                         order=['date','dayofweek','B_dt_index','B_day','source','content',\n",
    "#                                                'content_raw','retweet_count','favorite_count',\n",
    "#                                                'sentiment_scores','time_shift'])\n",
    "\n",
    "\n",
    "# # Make temporary B_dt_index var in order to round that column to minute-resolution\n",
    "# B_dt_index = twitter_df[['B_dt_index','B_day']]#.asfreq('T')\n",
    "# B_dt_index['B_dt_index']= pd.to_datetime(B_dt_index['B_dt_index'])\n",
    "# B_dt_index['B_dt_index']= B_dt_index['B_dt_index'].dt.round('T')\n",
    "\n",
    "# # Get stock_prices for each twitter timestamp\n",
    "# twitter_df['B_dt_minutes'] = B_dt_index['B_dt_index'].copy()\n",
    "# twitter_df['stock_price_results'] = twitter_df['B_dt_minutes'].apply(lambda x: match_stock_price_to_tweets(x,stock_price=stock_price))\n",
    "# df_to_add = twitter_df['stock_price_results'].apply(lambda x: unpack_match_stocks(x))\n",
    "\n",
    "# new_twitter_df = pd.concat([twitter_df,df_to_add], axis=1)\n",
    "\n",
    "\n",
    "# twitter_df = new_twitter_df.loc[~new_twitter_df['post_tweet_price'].isna()]\n",
    "# # twitter_df.drop(['0'],axis=1,inplace=True)\n",
    "# twitter_df['stock_delta_class'] = np.where(twitter_df['delta_price'] > 0,'pos','neg')\n",
    "\n",
    "# # display(twitter_df.head())\n",
    "# print(twitter_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "del twitter_df, stock_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_combined_BEST import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading stock_price\n",
      "Loading twitter_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "      <th>has_RT</th>\n",
       "      <th>starts_RT</th>\n",
       "      <th>content_starts_RT</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>content_min_clean</th>\n",
       "      <th>content_hashtags</th>\n",
       "      <th>hashtag_strings</th>\n",
       "      <th>content_mentions</th>\n",
       "      <th>mention_strings</th>\n",
       "      <th>clean_content_stop</th>\n",
       "      <th>clean_content_stop_tokens</th>\n",
       "      <th>case_ratio</th>\n",
       "      <th>sentiment_scores</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>sentiment_class</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-20 12:31:53</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>2017-01-20 12:31:53</td>\n",
       "      <td>70523</td>\n",
       "      <td>268372</td>\n",
       "      <td>False</td>\n",
       "      <td>822421390125043713</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>begins today see swearing movement continues w...</td>\n",
       "      <td>[begins, today, see, swearing, movement, conti...</td>\n",
       "      <td>0.3304</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:51:25</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>2017-01-20 17:51:25</td>\n",
       "      <td>20125</td>\n",
       "      <td>109640</td>\n",
       "      <td>False</td>\n",
       "      <td>822501803615014918</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>today merely transferring power one administra...</td>\n",
       "      <td>[today, merely, transferring, power, one, admi...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.919, 'pos': 0.081, 'comp...</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:51:58</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>2017-01-20 17:51:58</td>\n",
       "      <td>18362</td>\n",
       "      <td>91143</td>\n",
       "      <td>False</td>\n",
       "      <td>822501939267141634</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>[#InaugurationDay]</td>\n",
       "      <td>#InaugurationDay</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>power washington c giving back american people</td>\n",
       "      <td>[power, washington, c, giving, back, american,...</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:52:45</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>2017-01-20 17:52:45</td>\n",
       "      <td>42790</td>\n",
       "      <td>180394</td>\n",
       "      <td>False</td>\n",
       "      <td>822502135233384448</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>truly matters party controls government whethe...</td>\n",
       "      <td>[truly, matters, party, controls, government, ...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>{'neg': 0.079, 'neu': 0.776, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:53:17</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>2017-01-20 17:53:17</td>\n",
       "      <td>60604</td>\n",
       "      <td>218555</td>\n",
       "      <td>False</td>\n",
       "      <td>822502270503972872</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>january th remembered day people became rulers...</td>\n",
       "      <td>[january, th, remembered, day, people, became,...</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  source                                            content                date  retweet_count  favorite_count is_retweet              id_str  has_RT  starts_RT content_starts_RT                                      clean_content                                  content_min_clean    content_hashtags   hashtag_strings content_mentions mention_strings                                 clean_content_stop                          clean_content_stop_tokens  case_ratio                                   sentiment_scores  compound_score sentiment_class    neg    neu    pos\n",
       "date                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "2017-01-20 12:31:53  Twitter for Android  It all begins today! I will see you at 11:00 A... 2017-01-20 12:31:53          70523          268372      False  822421390125043713   False      False                []  It all begins today! I will see you at 11:00 A...  It all begins today! I will see you at 11:00 A...                  []                                 []                  begins today see swearing movement continues w...  [begins, today, see, swearing, movement, conti...      0.3304  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000             pos  0.000  1.000  0.000\n",
       "2017-01-20 17:51:25   Twitter for iPhone  Today we are not merely transferring power fro... 2017-01-20 17:51:25          20125          109640      False  822501803615014918   False      False                []  Today we are not merely transferring power fro...  Today we are not merely transferring power fro...                  []                                 []                  today merely transferring power one administra...  [today, merely, transferring, power, one, admi...      0.0148  {'neg': 0.0, 'neu': 0.919, 'pos': 0.081, 'comp...          0.2144             pos  0.000  0.919  0.081\n",
       "2017-01-20 17:51:58   Twitter for iPhone  power from Washington D.C. and giving it back ... 2017-01-20 17:51:58          18362           91143      False  822501939267141634   False      False                []  power from Washington D.C. and giving it back ...  power from Washington D.C. and giving it back ...  [#InaugurationDay]  #InaugurationDay               []                     power washington c giving back american people  [power, washington, c, giving, back, american,...      0.0778  {'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...          0.3400             pos  0.000  0.844  0.156\n",
       "2017-01-20 17:52:45   Twitter for iPhone  What truly matters is not which party controls... 2017-01-20 17:52:45          42790          180394      False  822502135233384448   False      False                []  What truly matters is not which party controls...  What truly matters is not which party controls...                  []                                 []                  truly matters party controls government whethe...  [truly, matters, party, controls, government, ...      0.0086  {'neg': 0.079, 'neu': 0.776, 'pos': 0.145, 'co...          0.0954             pos  0.079  0.776  0.145\n",
       "2017-01-20 17:53:17   Twitter for iPhone  January 20th 2017 will be remembered as the da... 2017-01-20 17:53:17          60604          218555      False  822502270503972872   False      False                []  January 20th 2017 will be remembered as the da...  January 20th 2017 will be remembered as the da...                  []                                 []                  january th remembered day people became rulers...  [january, th, remembered, day, people, became,...      0.0102  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000             pos  0.000  1.000  0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-20 09:30:00 2019-06-21 16:00:00\n",
      "2017-01-20 12:31:53 2019-06-20 00:12:31\n"
     ]
    }
   ],
   "source": [
    "##### MAKING ALL OF THE ABOVE STUFF INTO A FUNCTION\n",
    "# del twitter_df\n",
    "###   APPLYING FULL WORKFLOW WRITTEN ABOVE IN CODE ###\n",
    "## LOAD IN STOCK PRICE\n",
    "def load_twitter_df_stock_price():# del stock_price\n",
    "    try: stock_price\n",
    "    except NameError: stock_price = None\n",
    "    if stock_price is  None:    \n",
    "        print('loading stock_price')\n",
    "        stock_price = load_stock_price_series()\n",
    "    else:\n",
    "        print('using pre-existing stock_price')\n",
    "\n",
    "    # Make sure stock_price is loaded as minute data\n",
    "    stock_price = stock_price.asfreq('T')\n",
    "    stock_price.dropna(inplace=True)\n",
    "    stock_price.sort_index(inplace=True)\n",
    "\n",
    "    ## LOAD TWEETS, SELECT THE PROPER DATE RANGE AND COLUMNS\n",
    "    # twitter_df = load_twitter_df(verbose=0)\n",
    "    try: twitter_df\n",
    "    except NameError: twitter_df=None\n",
    "    if twitter_df is None:\n",
    "        print('Loading twitter_df')\n",
    "        twitter_df= load_raw_twitter_file()\n",
    "        twitter_df = full_twitter_df_processing(twitter_df,cleaned_tweet_col='clean_content')\n",
    "\n",
    "    stock_price.sort_index(inplace=True)\n",
    "    twitter_df.sort_index(inplace=True)\n",
    "    \n",
    "    display(twitter_df.head())\n",
    "    print(stock_price.index[0],stock_price.index[-1])\n",
    "    print(twitter_df.index[0],twitter_df.index[-1])\n",
    "    \n",
    "    return twitter_df, stock_price\n",
    "\n",
    "twitter_df,stock_price = load_twitter_df_stock_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-20 09:30:00 2019-06-21 16:00:00\n",
      "2017-01-20 12:31:53 2019-06-20 00:12:31\n"
     ]
    }
   ],
   "source": [
    "stock_price.sort_index(inplace=True)\n",
    "twitter_df.sort_index(inplace=True)\n",
    "print(stock_price.index[0],stock_price.index[-1])\n",
    "print(twitter_df.index[0],twitter_df.index[-1])\n",
    "# stock_price.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "      <th>has_RT</th>\n",
       "      <th>starts_RT</th>\n",
       "      <th>content_starts_RT</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>content_min_clean</th>\n",
       "      <th>content_hashtags</th>\n",
       "      <th>hashtag_strings</th>\n",
       "      <th>content_mentions</th>\n",
       "      <th>mention_strings</th>\n",
       "      <th>clean_content_stop</th>\n",
       "      <th>clean_content_stop_tokens</th>\n",
       "      <th>case_ratio</th>\n",
       "      <th>sentiment_scores</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>sentiment_class</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-20 12:31:53</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>2017-01-20 12:31:53</td>\n",
       "      <td>70523</td>\n",
       "      <td>268372</td>\n",
       "      <td>False</td>\n",
       "      <td>822421390125043713</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>begins today see swearing movement continues w...</td>\n",
       "      <td>[begins, today, see, swearing, movement, conti...</td>\n",
       "      <td>0.3304</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:51:25</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>2017-01-20 17:51:25</td>\n",
       "      <td>20125</td>\n",
       "      <td>109640</td>\n",
       "      <td>False</td>\n",
       "      <td>822501803615014918</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>today merely transferring power one administra...</td>\n",
       "      <td>[today, merely, transferring, power, one, admi...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.919, 'pos': 0.081, 'comp...</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:51:58</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>2017-01-20 17:51:58</td>\n",
       "      <td>18362</td>\n",
       "      <td>91143</td>\n",
       "      <td>False</td>\n",
       "      <td>822501939267141634</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>[#InaugurationDay]</td>\n",
       "      <td>#InaugurationDay</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>power washington c giving back american people</td>\n",
       "      <td>[power, washington, c, giving, back, american,...</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:52:45</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>2017-01-20 17:52:45</td>\n",
       "      <td>42790</td>\n",
       "      <td>180394</td>\n",
       "      <td>False</td>\n",
       "      <td>822502135233384448</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>truly matters party controls government whethe...</td>\n",
       "      <td>[truly, matters, party, controls, government, ...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>{'neg': 0.079, 'neu': 0.776, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:53:17</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>2017-01-20 17:53:17</td>\n",
       "      <td>60604</td>\n",
       "      <td>218555</td>\n",
       "      <td>False</td>\n",
       "      <td>822502270503972872</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>january th remembered day people became rulers...</td>\n",
       "      <td>[january, th, remembered, day, people, became,...</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  source                                            content                date  retweet_count  favorite_count is_retweet              id_str  has_RT  starts_RT content_starts_RT                                      clean_content                                  content_min_clean    content_hashtags   hashtag_strings content_mentions mention_strings                                 clean_content_stop                          clean_content_stop_tokens  case_ratio                                   sentiment_scores  compound_score sentiment_class    neg    neu    pos\n",
       "date                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "2017-01-20 12:31:53  Twitter for Android  It all begins today! I will see you at 11:00 A... 2017-01-20 12:31:53          70523          268372      False  822421390125043713   False      False                []  It all begins today! I will see you at 11:00 A...  It all begins today! I will see you at 11:00 A...                  []                                 []                  begins today see swearing movement continues w...  [begins, today, see, swearing, movement, conti...      0.3304  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000             pos  0.000  1.000  0.000\n",
       "2017-01-20 17:51:25   Twitter for iPhone  Today we are not merely transferring power fro... 2017-01-20 17:51:25          20125          109640      False  822501803615014918   False      False                []  Today we are not merely transferring power fro...  Today we are not merely transferring power fro...                  []                                 []                  today merely transferring power one administra...  [today, merely, transferring, power, one, admi...      0.0148  {'neg': 0.0, 'neu': 0.919, 'pos': 0.081, 'comp...          0.2144             pos  0.000  0.919  0.081\n",
       "2017-01-20 17:51:58   Twitter for iPhone  power from Washington D.C. and giving it back ... 2017-01-20 17:51:58          18362           91143      False  822501939267141634   False      False                []  power from Washington D.C. and giving it back ...  power from Washington D.C. and giving it back ...  [#InaugurationDay]  #InaugurationDay               []                     power washington c giving back american people  [power, washington, c, giving, back, american,...      0.0778  {'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...          0.3400             pos  0.000  0.844  0.156\n",
       "2017-01-20 17:52:45   Twitter for iPhone  What truly matters is not which party controls... 2017-01-20 17:52:45          42790          180394      False  822502135233384448   False      False                []  What truly matters is not which party controls...  What truly matters is not which party controls...                  []                                 []                  truly matters party controls government whethe...  [truly, matters, party, controls, government, ...      0.0086  {'neg': 0.079, 'neu': 0.776, 'pos': 0.145, 'co...          0.0954             pos  0.079  0.776  0.145\n",
       "2017-01-20 17:53:17   Twitter for iPhone  January 20th 2017 will be remembered as the da... 2017-01-20 17:53:17          60604          218555      False  822502270503972872   False      False                []  January 20th 2017 will be remembered as the da...  January 20th 2017 will be remembered as the da...                  []                                 []                  january th remembered day people became rulers...  [january, th, remembered, day, people, became,...      0.0102  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000             pos  0.000  1.000  0.000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit tweets by avialable stock data    \n",
    "twitter_df = twitter_df.loc[stock_price.index[0]:stock_price.index[-1]]\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "------ SOURCE ----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def match_stock_price_to_tweets(tweet_timestamp,time_after_tweet= 60,time_freq ='T',stock_price=[]):#stock_price_index=stock_date_data):\n",
       "    \n",
       "    import pandas as pd\n",
       "    import numpy as np\n",
       "    from datetime import datetime as dt\n",
       "    # output={'pre_tweet_price': price_at_tweet,'post_tweet_price':price_after_tweet,'delta_price':delta_price, 'delta_time':delta_time}\n",
       "    output={}\n",
       "    # convert tweet timestamp to minute accuracy\n",
       "    ts=[]\n",
       "    ts = pd.to_datetime(tweet_timestamp).round(time_freq)\n",
       "    \n",
       "    BH = pd.tseries.offsets.BusinessHour(start='09:30',end='16:30')\n",
       "    BD = pd.tseries.offsets.BusinessDay()\n",
       "    \n",
       "    \n",
       "    # checking if time is within stock_date_data\n",
       "#     def roll_B_day_forward(ts):\n",
       "     \n",
       "    if ts not in stock_price.index:\n",
       "        ts = BH.rollforward(ts)   \n",
       "\n",
       "        \n",
       "        if ts not in stock_price.index:\n",
       "            return np.nan#\"ts2_not_in_index\"\n",
       "\n",
       "    # Get price at tweet time\n",
       "    price_at_tweet = stock_price.loc[ts]\n",
       "    output['B_ts_rounded'] = ts\n",
       "\n",
       "\n",
       "    if np.isnan(price_at_tweet):\n",
       "        output['pre_tweet_price'] = np.nan\n",
       "    else: \n",
       "        output['pre_tweet_price'] = price_at_tweet\n",
       "\n",
       "    output['mins_after_tweet'] = time_after_tweet\n",
       "               \n",
       "        \n",
       "    # Use timedelta to get desired timepoint following tweet\n",
       "    hour_freqs = 'BH','H','CBH'\n",
       "    day_freqs = 'B','D'\n",
       "\n",
       "    if time_freq=='T':\n",
       "        ofst=pd.offsets.Minute(time_after_tweet)\n",
       "\n",
       "    elif time_freq in hour_freqs:\n",
       "        ofst=pd.offsets.Hour(time_after_tweet)\n",
       "\n",
       "    elif time_freq in day_freqs:\n",
       "        ofst=pd.offsets.Day(time_after_tweet)\n",
       "\n",
       "\n",
       "    # get timestamp to check post-tweet price\n",
       "    post_tweet_ts = ofst(ts)\n",
       "\n",
       "    \n",
       "    if post_tweet_ts not in stock_price.index:\n",
       "#         post_tweet_ts =BD.rollforward(post_tweet_ts)\n",
       "        post_tweet_ts = BH.rollforward(post_tweet_ts)\n",
       "    \n",
       "        if post_tweet_ts not in stock_price.index:\n",
       "            return np.nan\n",
       "\n",
       "    output['B_ts_post_tweet'] = post_tweet_ts\n",
       "\n",
       "    # Get next available stock price\n",
       "    price_after_tweet = stock_price.loc[post_tweet_ts]\n",
       "    if np.isnan(price_after_tweet):\n",
       "        output['post_tweet_price'] = 'NaN in stock_price'\n",
       "    else:\n",
       "        # calculate change in price\n",
       "        delta_price = price_after_tweet - price_at_tweet\n",
       "        delta_time = post_tweet_ts - ts\n",
       "        output['post_tweet_price'] = price_after_tweet\n",
       "        output['delta_time'] = delta_time\n",
       "        output['delta_price'] = delta_price\n",
       "\n",
       "#         output={'pre_tweet_price': price_at_tweet,'post_tweet_price':price_after_tweet,'delta_price':delta_price, 'delta_time':delta_time}\n",
       "\n",
       "    # reorder_output_cols  = ['B_dt_index','pre_tweet_price','']\n",
       "    # reorder_output \n",
       "    return output\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ihelp(match_stock_price_to_tweets,show_help=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "      <th>has_RT</th>\n",
       "      <th>starts_RT</th>\n",
       "      <th>content_starts_RT</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>content_min_clean</th>\n",
       "      <th>content_hashtags</th>\n",
       "      <th>hashtag_strings</th>\n",
       "      <th>content_mentions</th>\n",
       "      <th>mention_strings</th>\n",
       "      <th>clean_content_stop</th>\n",
       "      <th>clean_content_stop_tokens</th>\n",
       "      <th>case_ratio</th>\n",
       "      <th>sentiment_scores</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>sentiment_class</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-20 12:31:53</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>2017-01-20 12:31:53</td>\n",
       "      <td>70523</td>\n",
       "      <td>268372</td>\n",
       "      <td>False</td>\n",
       "      <td>822421390125043713</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>begins today see swearing movement continues w...</td>\n",
       "      <td>[begins, today, see, swearing, movement, conti...</td>\n",
       "      <td>0.3304</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:51:25</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>2017-01-20 17:51:25</td>\n",
       "      <td>20125</td>\n",
       "      <td>109640</td>\n",
       "      <td>False</td>\n",
       "      <td>822501803615014918</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>today merely transferring power one administra...</td>\n",
       "      <td>[today, merely, transferring, power, one, admi...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.919, 'pos': 0.081, 'comp...</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:51:58</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>2017-01-20 17:51:58</td>\n",
       "      <td>18362</td>\n",
       "      <td>91143</td>\n",
       "      <td>False</td>\n",
       "      <td>822501939267141634</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>[#InaugurationDay]</td>\n",
       "      <td>#InaugurationDay</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>power washington c giving back american people</td>\n",
       "      <td>[power, washington, c, giving, back, american,...</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:52:45</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>2017-01-20 17:52:45</td>\n",
       "      <td>42790</td>\n",
       "      <td>180394</td>\n",
       "      <td>False</td>\n",
       "      <td>822502135233384448</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>truly matters party controls government whethe...</td>\n",
       "      <td>[truly, matters, party, controls, government, ...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>{'neg': 0.079, 'neu': 0.776, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:53:17</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>2017-01-20 17:53:17</td>\n",
       "      <td>60604</td>\n",
       "      <td>218555</td>\n",
       "      <td>False</td>\n",
       "      <td>822502270503972872</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>january th remembered day people became rulers...</td>\n",
       "      <td>[january, th, remembered, day, people, became,...</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  source                                            content                date  retweet_count  favorite_count is_retweet              id_str  has_RT  starts_RT content_starts_RT                                      clean_content                                  content_min_clean    content_hashtags   hashtag_strings content_mentions mention_strings                                 clean_content_stop                          clean_content_stop_tokens  case_ratio                                   sentiment_scores  compound_score sentiment_class    neg    neu    pos\n",
       "date                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "2017-01-20 12:31:53  Twitter for Android  It all begins today! I will see you at 11:00 A... 2017-01-20 12:31:53          70523          268372      False  822421390125043713   False      False                []  It all begins today! I will see you at 11:00 A...  It all begins today! I will see you at 11:00 A...                  []                                 []                  begins today see swearing movement continues w...  [begins, today, see, swearing, movement, conti...      0.3304  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000             pos  0.000  1.000  0.000\n",
       "2017-01-20 17:51:25   Twitter for iPhone  Today we are not merely transferring power fro... 2017-01-20 17:51:25          20125          109640      False  822501803615014918   False      False                []  Today we are not merely transferring power fro...  Today we are not merely transferring power fro...                  []                                 []                  today merely transferring power one administra...  [today, merely, transferring, power, one, admi...      0.0148  {'neg': 0.0, 'neu': 0.919, 'pos': 0.081, 'comp...          0.2144             pos  0.000  0.919  0.081\n",
       "2017-01-20 17:51:58   Twitter for iPhone  power from Washington D.C. and giving it back ... 2017-01-20 17:51:58          18362           91143      False  822501939267141634   False      False                []  power from Washington D.C. and giving it back ...  power from Washington D.C. and giving it back ...  [#InaugurationDay]  #InaugurationDay               []                     power washington c giving back american people  [power, washington, c, giving, back, american,...      0.0778  {'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...          0.3400             pos  0.000  0.844  0.156\n",
       "2017-01-20 17:52:45   Twitter for iPhone  What truly matters is not which party controls... 2017-01-20 17:52:45          42790          180394      False  822502135233384448   False      False                []  What truly matters is not which party controls...  What truly matters is not which party controls...                  []                                 []                  truly matters party controls government whethe...  [truly, matters, party, controls, government, ...      0.0086  {'neg': 0.079, 'neu': 0.776, 'pos': 0.145, 'co...          0.0954             pos  0.079  0.776  0.145\n",
       "2017-01-20 17:53:17   Twitter for iPhone  January 20th 2017 will be remembered as the da... 2017-01-20 17:53:17          60604          218555      False  822502270503972872   False      False                []  January 20th 2017 will be remembered as the da...  January 20th 2017 will be remembered as the da...                  []                                 []                  january th remembered day people became rulers...  [january, th, remembered, day, people, became,...      0.0102  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000             pos  0.000  1.000  0.000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# twitter_df = twitter_df[['date','source','content','content_raw','retweet_count','favorite_count','sentiment_scores']]\n",
    "# twitter_df.head()\n",
    "\n",
    "# Reorder Columns to desired order\n",
    "# order=['date','dayofweek','B_dt_index','B_day','source','content','content_raw','retweet_count','favorite_count',\n",
    "#                                                'sentiment_scores','time_shift']\n",
    "# twitter_df = reorder_twitter_df_columns(twitter_df, order=order)\n",
    "\n",
    "def get_stock_prices_for_twitter_data(twitter_df, stock_prices):\n",
    "    # Get get the business day index to account for tweets during off-hours\n",
    "    twitter_df = get_B_day_time_index_shift(twitter_df,verbose=1)\n",
    "\n",
    "    # Make temporary B_dt_index var in order to round that column to minute-resolution\n",
    "    B_dt_index = twitter_df[['B_dt_index','B_day']]#.asfreq('T')\n",
    "    B_dt_index['B_dt_index']= pd.to_datetime(B_dt_index['B_dt_index'])\n",
    "    B_dt_index['B_dt_index']= B_dt_index['B_dt_index'].dt.round('T')\n",
    "\n",
    "    # Get stock_prices for each twitter timestamp\n",
    "    twitter_df['B_dt_minutes'] = B_dt_index['B_dt_index'].copy()\n",
    "    twitter_df['stock_price_results'] = twitter_df['B_dt_minutes'].apply(lambda x: match_stock_price_to_tweets(x,time_after_tweet=60,stock_price=stock_price))\n",
    "    \n",
    "    df_to_add = twitter_df['stock_price_results'].apply(lambda x: unpack_match_stocks(x))\n",
    "\n",
    "    new_twitter_df = pd.concat([twitter_df,df_to_add], axis=1)\n",
    "\n",
    "\n",
    "    twitter_df = new_twitter_df.loc[~new_twitter_df['post_tweet_price'].isna()]\n",
    "    # twitter_df.drop(['0'],axis=1,inplace=True)\n",
    "    twitter_df['delta_price_class'] = np.where(twitter_df['delta_price'] > 0,'pos','neg')\n",
    "\n",
    "    twitter_df.drop([0],axis=1, inplace=True)\n",
    "    # display(twitter_df.head())\n",
    "    print(twitter_df.isna().sum())\n",
    "    \n",
    "    return twitter_df\n",
    "\n",
    "\n",
    "twitter_df = ji.get_stock_prices_for_twitter_data(twitter_df,stock_price)\n",
    "twitter_df.head()\n",
    "df_tokenize=twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport\n",
    "# ProfileReport(test_df.drop(['date','stock_price_results'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['delta_price'].hist(bins=20)\n",
    "# test_df['delta_time'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### TROUBLESHOOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check_df = twitter_df.loc[twitter_df['stock_price_results'].isna()]#.sum()\n",
    "# BH = pd.tseries.offsets.BusinessHour(start='09:30',end='16:30')\n",
    "# BD = pd.tseries.offsets.BusinessDay()\n",
    "# check_df.head()\n",
    "\n",
    "# check_times = check_df['B_dt_minutes']\n",
    "# ofst = pd.offsets.Minute(30)\n",
    "# np.sum([x in stock_price.index for x in check_times])\n",
    "\n",
    "# # Example\n",
    "# ct = check_times[0]\n",
    "# print(ct)\n",
    "# ct_oft = ofst(ct)\n",
    "# print(ct_oft)\n",
    "# print(ct_oft in stock_price.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# stock_price.loc['2017-01-26 11:00':'2017-01-26 12:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # twitter_df['stock_price_results'] has:\n",
    "#     # dict_keys(['pre_tweet_price', 'post_tweet_price', 'delta_price', 'delta_time'])\n",
    "# test_dict = twitter_df['stock_price_results'][0]\n",
    "# if skip==False:\n",
    "#     def unpack_match_stocks(stock_dict):\n",
    "#         stock_series = pd.Series(stock_dict)\n",
    "#         return stock_series\n",
    "# # display(twitter_df['stock_price_results'].head())\n",
    "# new_df = twitter_df[['stock_price_results','B_dt_minutes']].copy()\n",
    "# new_df2 = twitter_df['stock_price_results'].apply(lambda x: unpack_match_stocks(x))\n",
    "# new_df = pd.concat([new_df,new_df2],axis=1)\n",
    "# display(new_df.head(10))\n",
    "# display(new_df.info())\n",
    "# # new_df.isna().sum() /len(new_df)\n",
    "# new_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# bad_times = new_df['B_dt_minutes']\n",
    "# stock_price.loc[bad_times[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # TROUBLESHOOTING\n",
    "# bad_tweets = twitter_df.loc[new_df['pre_tweet_price']=='NaN in stock_price']\n",
    "# # bad_tweets = bad_tweets[['B_day','dayofweek','B_dt_minutes','time_shift','stock_price_results']]\n",
    "# bad_tweets.drop(['source','content','content_raw','retweet_count','favorite_count','date','B_dt_index'], axis=1, inplace=True)\n",
    "# # print(stock_price.index)\n",
    "# display(bad_tweets.head(20))\n",
    "# print(bad_tweets.info())\n",
    "# print(len(bad_tweets),len(twitter_df))\n",
    "# # print(bad_tweets.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# bad_TS = bad_tweets['B_dt_minutes']\n",
    "# BH = pd.tseries.offsets.BusinessHour(start='09:30',end='16:30')\n",
    "\n",
    "# TS = bad_TS[0]\n",
    "# print(TS)\n",
    "# test_ts = BH.rollforward(TS)\n",
    "# test_roll = bad_TS.apply(lambda x: BH.rollforward(x))\n",
    "# # BH, test_ts\n",
    "# test_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # TROUBLESHOOTING\n",
    "# bad_tweets = twitter_df.loc[twitter_df['stock_price_results'].isna()]\n",
    "# print(stock_price.index)\n",
    "# bad_tweets.head()\n",
    "# # print(bad_tweets.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ## FUNCTION CODE\n",
    "# import pandas as pd\n",
    "# from datetime import datetime as dt\n",
    "# tweet_timestamp = bad_tweets.sample(1).index\n",
    "# print(tweet_timestamp)\n",
    "# # convert tweet timestamp to minute accuracy\n",
    "# ts=[]\n",
    "# ts = pd.to_datetime(tweet_timestamp).round(time_freq)\n",
    "# print('Rounded: ',ts)\n",
    "# CBH =custom_BH_freq()      \n",
    "# BH = pd.tseries.offsets.BusinessHour(start='09:30',end='04:30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # checking if time is within stock_date_data\n",
    "# if ts not in stock_price.index:\n",
    "    \n",
    "#     ts2 = BH.rollforward(pd.to_datetime(ts))\n",
    "# #     ts2 = CBH.rollforward(ts) \n",
    "#     print(f'ts prior: {ts}\\tts post_roll: {ts2}')\n",
    "# #     if ts2 not in stock_price.index:\n",
    "# #         print('ts2 Not in index:',ts2)\n",
    "# #     else: \n",
    "# #         print('ts2 is in index',ts2)\n",
    "# #         ts=ts2\n",
    "\n",
    "# # bad_tweets['B_dt_index'][1:10].apply(lambda x: match_stock_price_to_tweets(x,stock_price=stock_price))\n",
    "# # twitter_df.loc[twitter_df['stock_price_results'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# twitter_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# twitter_df.loc'2017-01-26 11:34:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOW:\n",
    "\n",
    "- Use `df_tweets['B_dt_index']` for `match_stock_price_to_tweets`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOKMARK- CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['pos' for x in twitter_df['delta_price'] if x>0 else 'neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD IN TWITTER DF AND STOCK PRICE \n",
    "twitter_df = ji.get_stock_prices_for_twitter_data(twitter_df,stock_price)\n",
    "twitter_df.head(3)\n",
    "df_tokenize=twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tokenize=twitter_df[['date','content','content_raw','B_dt_minutes','pre_tweet_price','post_tweet_price','delta_price']].copy()\n",
    "                        \n",
    "df_tokenize.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE /LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tokenize.to_csv('twitter_df_with_matched_price_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_combined_BEST import make_stopwords_list, apply_stopwords, full_twitter_df_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df =full_twitter_df_processing(df_tokenize,cleaned_tweet_col='final_tweet')\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Generate Stopwords List from nltk + punctuation + custom list\n",
    "# from nltk import regexp_tokenize\n",
    "# pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "# import string\n",
    "\n",
    "# stopwords_list = stopwords.words('english')\n",
    "# stopwords_list += list(string.punctuation)\n",
    "# stopwords_list += ['http','https','...','…','``','co','“','’','‘','”',\"n't\",\"''\",'u','s',\"'s\",'|','\\\\|','amp',\"i'm\"]\n",
    "# stopwords_list += [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "# ## Adding in stopword removal to the actual dataframe\n",
    "# def apply_stopwords(stopwords_list,  text, tokenize=True, pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"):\n",
    "\n",
    "#     if tokenize==True:\n",
    "#         from nltk import regexp_tokenize\n",
    "        \n",
    "#         text = regexp_tokenize(text,pattern)\n",
    "        \n",
    "#     stopped = [x.lower() for x in text if x.lower() not in stopwords_list]\n",
    "#     return ' '.join(stopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # Save 'hashtags' column containing all hastags\n",
    "# import re\n",
    "# df=twitter_df.copy()\n",
    "# # df['content_raw'] = df['content'].copy()\n",
    "\n",
    "# # Add has_RT and starts_RT columns\n",
    "# # Creating columns for tweets that `has_RT` or `starts_RT`\n",
    "# df['has_RT']=df['content_raw'].str.contains('RT')\n",
    "# df['starts_RT']=df['content_raw'].str.contains('^RT')\n",
    "\n",
    "# ## FIRST REMOVE THE RT HEADERS\n",
    "\n",
    "# # Remove `RT @Mentions` FIRST:\n",
    "# re_RT = re.compile('RT [@]?\\w*:')\n",
    "\n",
    "# raw_col =  'content_raw'\n",
    "# check_content_col =raw_col\n",
    "# fill_content_col = 'content'\n",
    "\n",
    "# df['content_starts_RT'] = df[check_content_col].apply(lambda x: re_RT.findall(x))\n",
    "# df[fill_content_col] =  df[check_content_col].apply(lambda x: re_RT.sub(' ',x))\n",
    "\n",
    "\n",
    "# ## SECOND REMOVE URLS\n",
    "# # Remove urls with regex\n",
    "# urls = re.compile(r\"(http[s]?://\\w*\\.\\w*/+\\w+)\")\n",
    "\n",
    "# check_content_col = 'content'\n",
    "# fill_content_col = 'content'\n",
    "\n",
    "# # df_full['content_urls'] = df_full[check_content_col].apply(lambda x: urls.findall(x))\n",
    "# df[fill_content_col] =  df[check_content_col].apply(lambda x: urls.sub(' ',x))\n",
    "\n",
    "# ## SAVE THIS MINIMALLY CLEANED CONTENT AS 'content_min_clean'\n",
    "# df['content_min_clean'] =  df[fill_content_col]\n",
    "\n",
    "\n",
    "\n",
    "# ## REMOVE AND SAVE HASHTAGS, MENTIONS\n",
    "# # Remove and save Hashtags\n",
    "# hashtags = re.compile(r'\\#\\w*')\n",
    "\n",
    "# check_content_col = 'content'\n",
    "# fill_content_col = 'content'\n",
    "\n",
    "# df['content_hashtags'] =  df[check_content_col].apply(lambda x: hashtags.findall(x))\n",
    "# df[fill_content_col] =  df[check_content_col].apply(lambda x: hashtags.sub(' ',x))\n",
    "\n",
    "\n",
    "# # Remove and save mentions (@)'s\n",
    "# mentions = re.compile(r'\\@\\w*')\n",
    "\n",
    "# check_content_col = 'content'\n",
    "# fill_content_col = 'content'\n",
    "\n",
    "# df['content_mentions'] =  df[check_content_col].apply(lambda x: mentions.findall(x))\n",
    "# df[fill_content_col] =  df[check_content_col].apply(lambda x: mentions.sub(' ',x))\n",
    "\n",
    "\n",
    "# # Creating content_stopped columns and then tokens_stopped column\n",
    "# df['content_stopped'] = df['content'].apply(lambda x: apply_stopwords(stopwords_list,x))\n",
    "# df['tokens_stopped'] = df['content_stopped'].apply(lambda x: regexp_tokenize(x,pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenize = twitter_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP NEURAL NETWORK _ MOD 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs_ds  v0.8.9 loaded.  Read the docs: https://bs-ds.readthedocs.io/en/latest/index.html\n",
      "For convenient loading of standard modules use: from bs_ds.imports import *\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371f\" ><caption>Loaded Packages and Handles</caption><thead>    <tr>        <th class=\"col_heading level0 col0\" >Package</th>        <th class=\"col_heading level0 col1\" >Handle</th>        <th class=\"col_heading level0 col2\" >Description</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow0_col0\" class=\"data row0 col0\" >bs_ds</td>\n",
       "                        <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow0_col1\" class=\"data row0 col1\" >bs</td>\n",
       "                        <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow0_col2\" class=\"data row0 col2\" >Custom data science bootcamp student package</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow1_col0\" class=\"data row1 col0\" >matplotlib</td>\n",
       "                        <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow1_col1\" class=\"data row1 col1\" >mpl</td>\n",
       "                        <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow1_col2\" class=\"data row1 col2\" >Matplotlib's base OOP module with formatting artists</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow2_col0\" class=\"data row2 col0\" >matplotlib.pyplot</td>\n",
       "                        <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow2_col1\" class=\"data row2 col1\" >plt</td>\n",
       "                        <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow2_col2\" class=\"data row2 col2\" >Matplotlib's matlab-like plotting module</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow3_col0\" class=\"data row3 col0\" >numpy</td>\n",
       "                        <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow3_col1\" class=\"data row3 col1\" >np</td>\n",
       "                        <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow3_col2\" class=\"data row3 col2\" >scientific computing with Python</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow4_col0\" class=\"data row4 col0\" >pandas</td>\n",
       "                        <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow4_col1\" class=\"data row4 col1\" >pd</td>\n",
       "                        <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow4_col2\" class=\"data row4 col2\" >High performance data structures and tools</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow5_col0\" class=\"data row5 col0\" >seaborn</td>\n",
       "                        <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow5_col1\" class=\"data row5 col1\" >sns</td>\n",
       "                        <td id=\"T_879c4654_baaa_11e9_9a3f_f48e38b6371frow5_col2\" class=\"data row5 col2\" >High-level data visualization library based on matplotlib</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2c543d7d048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "display.max_columns=None\n",
      "display.expand_frame_repr=False\n",
      "display.max_rows=None\n",
      "display.max_info_columns=500\n",
      "display.precision=4\n",
      "Reloading my_keras_functions...\n",
      "Reloading functions_combined_BEST...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'functions_combined_BEST' from 'D:\\\\Users\\\\James\\\\Dropbox (Personal)\\\\CODING\\\\_FLATIRON\\\\Mod5_FinalProject\\\\dsc-5-capstone-project-online-ds-ft-021119\\\\functions_combined_BEST.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import some functions directly\n",
    "from functions_combined_BEST import ihelp, ihelp_menu, reload\n",
    "\n",
    "\n",
    "## IMPORT STANDARD PACKAGES\n",
    "from bs_ds.imports import *\n",
    "from pprint import pprint\n",
    "\n",
    "# Import my custom functions \n",
    "import functions_combined_BEST as ji\n",
    "import my_keras_functions as jik\n",
    "import function_widgets as fw\n",
    "import bs_ds as bs\n",
    "\n",
    "# Import plotly and cufflinks for iplots\n",
    "import plotly\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "\n",
    "\n",
    "bs.big_pandas()\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reload modules in case files have been updated\n",
    "reload(jik)\n",
    "reload(ji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading stock_price\n",
      "Loading twitter_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "      <th>has_RT</th>\n",
       "      <th>starts_RT</th>\n",
       "      <th>content_starts_RT</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>content_min_clean</th>\n",
       "      <th>content_hashtags</th>\n",
       "      <th>hashtag_strings</th>\n",
       "      <th>content_mentions</th>\n",
       "      <th>mention_strings</th>\n",
       "      <th>clean_content_stop</th>\n",
       "      <th>clean_content_stop_tokens</th>\n",
       "      <th>case_ratio</th>\n",
       "      <th>sentiment_scores</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>sentiment_class</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-20 12:31:53</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>2017-01-20 12:31:53</td>\n",
       "      <td>70523</td>\n",
       "      <td>268372</td>\n",
       "      <td>False</td>\n",
       "      <td>822421390125043713</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>begins today see swearing movement continues w...</td>\n",
       "      <td>[begins, today, see, swearing, movement, conti...</td>\n",
       "      <td>0.3304</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:51:25</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>2017-01-20 17:51:25</td>\n",
       "      <td>20125</td>\n",
       "      <td>109640</td>\n",
       "      <td>False</td>\n",
       "      <td>822501803615014918</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>today merely transferring power one administra...</td>\n",
       "      <td>[today, merely, transferring, power, one, admi...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.919, 'pos': 0.081, 'comp...</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:51:58</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>2017-01-20 17:51:58</td>\n",
       "      <td>18362</td>\n",
       "      <td>91143</td>\n",
       "      <td>False</td>\n",
       "      <td>822501939267141634</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>[#InaugurationDay]</td>\n",
       "      <td>#InaugurationDay</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>power washington c giving back american people</td>\n",
       "      <td>[power, washington, c, giving, back, american,...</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:52:45</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>2017-01-20 17:52:45</td>\n",
       "      <td>42790</td>\n",
       "      <td>180394</td>\n",
       "      <td>False</td>\n",
       "      <td>822502135233384448</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>truly matters party controls government whethe...</td>\n",
       "      <td>[truly, matters, party, controls, government, ...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>{'neg': 0.079, 'neu': 0.776, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:53:17</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>2017-01-20 17:53:17</td>\n",
       "      <td>60604</td>\n",
       "      <td>218555</td>\n",
       "      <td>False</td>\n",
       "      <td>822502270503972872</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>january th remembered day people became rulers...</td>\n",
       "      <td>[january, th, remembered, day, people, became,...</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  source                                            content                date  retweet_count  favorite_count is_retweet              id_str  has_RT  starts_RT content_starts_RT                                      clean_content                                  content_min_clean    content_hashtags   hashtag_strings content_mentions mention_strings                                 clean_content_stop                          clean_content_stop_tokens  case_ratio                                   sentiment_scores  compound_score sentiment_class    neg    neu    pos\n",
       "date                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "2017-01-20 12:31:53  Twitter for Android  It all begins today! I will see you at 11:00 A... 2017-01-20 12:31:53          70523          268372      False  822421390125043713   False      False                []  It all begins today! I will see you at 11:00 A...  It all begins today! I will see you at 11:00 A...                  []                                 []                  begins today see swearing movement continues w...  [begins, today, see, swearing, movement, conti...      0.3304  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000             pos  0.000  1.000  0.000\n",
       "2017-01-20 17:51:25   Twitter for iPhone  Today we are not merely transferring power fro... 2017-01-20 17:51:25          20125          109640      False  822501803615014918   False      False                []  Today we are not merely transferring power fro...  Today we are not merely transferring power fro...                  []                                 []                  today merely transferring power one administra...  [today, merely, transferring, power, one, admi...      0.0148  {'neg': 0.0, 'neu': 0.919, 'pos': 0.081, 'comp...          0.2144             pos  0.000  0.919  0.081\n",
       "2017-01-20 17:51:58   Twitter for iPhone  power from Washington D.C. and giving it back ... 2017-01-20 17:51:58          18362           91143      False  822501939267141634   False      False                []  power from Washington D.C. and giving it back ...  power from Washington D.C. and giving it back ...  [#InaugurationDay]  #InaugurationDay               []                     power washington c giving back american people  [power, washington, c, giving, back, american,...      0.0778  {'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...          0.3400             pos  0.000  0.844  0.156\n",
       "2017-01-20 17:52:45   Twitter for iPhone  What truly matters is not which party controls... 2017-01-20 17:52:45          42790          180394      False  822502135233384448   False      False                []  What truly matters is not which party controls...  What truly matters is not which party controls...                  []                                 []                  truly matters party controls government whethe...  [truly, matters, party, controls, government, ...      0.0086  {'neg': 0.079, 'neu': 0.776, 'pos': 0.145, 'co...          0.0954             pos  0.079  0.776  0.145\n",
       "2017-01-20 17:53:17   Twitter for iPhone  January 20th 2017 will be remembered as the da... 2017-01-20 17:53:17          60604          218555      False  822502270503972872   False      False                []  January 20th 2017 will be remembered as the da...  January 20th 2017 will be remembered as the da...                  []                                 []                  january th remembered day people became rulers...  [january, th, remembered, day, people, became,...      0.0102  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000             pos  0.000  1.000  0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-20 09:30:00 2019-06-21 16:00:00\n",
      "2017-01-20 12:31:53 2019-06-20 00:12:31\n"
     ]
    }
   ],
   "source": [
    "# twitter_df,stock_price = ji.load_twitter_df_stock_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading my_keras_functions...\n",
      "Reloading functions_combined_BEST...\n",
      "loading stock_price\n",
      "Loading twitter_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "      <th>has_RT</th>\n",
       "      <th>starts_RT</th>\n",
       "      <th>content_starts_RT</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>content_min_clean</th>\n",
       "      <th>content_hashtags</th>\n",
       "      <th>hashtag_strings</th>\n",
       "      <th>content_mentions</th>\n",
       "      <th>mention_strings</th>\n",
       "      <th>clean_content_stop</th>\n",
       "      <th>clean_content_stop_tokens</th>\n",
       "      <th>case_ratio</th>\n",
       "      <th>sentiment_scores</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>sentiment_class</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-20 12:31:53</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>2017-01-20 12:31:53</td>\n",
       "      <td>70523</td>\n",
       "      <td>268372</td>\n",
       "      <td>False</td>\n",
       "      <td>822421390125043713</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>begins today see swearing movement continues w...</td>\n",
       "      <td>[begins, today, see, swearing, movement, conti...</td>\n",
       "      <td>0.3304</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:51:25</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>2017-01-20 17:51:25</td>\n",
       "      <td>20125</td>\n",
       "      <td>109640</td>\n",
       "      <td>False</td>\n",
       "      <td>822501803615014918</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>today merely transferring power one administra...</td>\n",
       "      <td>[today, merely, transferring, power, one, admi...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.919, 'pos': 0.081, 'comp...</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:51:58</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>2017-01-20 17:51:58</td>\n",
       "      <td>18362</td>\n",
       "      <td>91143</td>\n",
       "      <td>False</td>\n",
       "      <td>822501939267141634</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>[#InaugurationDay]</td>\n",
       "      <td>#InaugurationDay</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>power washington c giving back american people</td>\n",
       "      <td>[power, washington, c, giving, back, american,...</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:52:45</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>2017-01-20 17:52:45</td>\n",
       "      <td>42790</td>\n",
       "      <td>180394</td>\n",
       "      <td>False</td>\n",
       "      <td>822502135233384448</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>What truly matters is not which party controls...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>truly matters party controls government whethe...</td>\n",
       "      <td>[truly, matters, party, controls, government, ...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>{'neg': 0.079, 'neu': 0.776, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:53:17</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>2017-01-20 17:53:17</td>\n",
       "      <td>60604</td>\n",
       "      <td>218555</td>\n",
       "      <td>False</td>\n",
       "      <td>822502270503972872</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>January 20th 2017 will be remembered as the da...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>january th remembered day people became rulers...</td>\n",
       "      <td>[january, th, remembered, day, people, became,...</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  source                                            content                date  retweet_count  favorite_count is_retweet              id_str  has_RT  starts_RT content_starts_RT                                      clean_content                                  content_min_clean    content_hashtags   hashtag_strings content_mentions mention_strings                                 clean_content_stop                          clean_content_stop_tokens  case_ratio                                   sentiment_scores  compound_score sentiment_class    neg    neu    pos\n",
       "date                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "2017-01-20 12:31:53  Twitter for Android  It all begins today! I will see you at 11:00 A... 2017-01-20 12:31:53          70523          268372      False  822421390125043713   False      False                []  It all begins today! I will see you at 11:00 A...  It all begins today! I will see you at 11:00 A...                  []                                 []                  begins today see swearing movement continues w...  [begins, today, see, swearing, movement, conti...      0.3304  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000             pos  0.000  1.000  0.000\n",
       "2017-01-20 17:51:25   Twitter for iPhone  Today we are not merely transferring power fro... 2017-01-20 17:51:25          20125          109640      False  822501803615014918   False      False                []  Today we are not merely transferring power fro...  Today we are not merely transferring power fro...                  []                                 []                  today merely transferring power one administra...  [today, merely, transferring, power, one, admi...      0.0148  {'neg': 0.0, 'neu': 0.919, 'pos': 0.081, 'comp...          0.2144             pos  0.000  0.919  0.081\n",
       "2017-01-20 17:51:58   Twitter for iPhone  power from Washington D.C. and giving it back ... 2017-01-20 17:51:58          18362           91143      False  822501939267141634   False      False                []  power from Washington D.C. and giving it back ...  power from Washington D.C. and giving it back ...  [#InaugurationDay]  #InaugurationDay               []                     power washington c giving back american people  [power, washington, c, giving, back, american,...      0.0778  {'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...          0.3400             pos  0.000  0.844  0.156\n",
       "2017-01-20 17:52:45   Twitter for iPhone  What truly matters is not which party controls... 2017-01-20 17:52:45          42790          180394      False  822502135233384448   False      False                []  What truly matters is not which party controls...  What truly matters is not which party controls...                  []                                 []                  truly matters party controls government whethe...  [truly, matters, party, controls, government, ...      0.0086  {'neg': 0.079, 'neu': 0.776, 'pos': 0.145, 'co...          0.0954             pos  0.079  0.776  0.145\n",
       "2017-01-20 17:53:17   Twitter for iPhone  January 20th 2017 will be remembered as the da... 2017-01-20 17:53:17          60604          218555      False  822502270503972872   False      False                []  January 20th 2017 will be remembered as the da...  January 20th 2017 will be remembered as the da...                  []                                 []                  january th remembered day people became rulers...  [january, th, remembered, day, people, became,...      0.0102  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000             pos  0.000  1.000  0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-20 09:30:00 2019-06-21 16:00:00\n",
      "2017-01-20 12:31:53 2019-06-20 00:12:31\n",
      "--- CLOCK STARTED @:    08/09/19 - 09:36:57 AM --- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "      <th>has_RT</th>\n",
       "      <th>starts_RT</th>\n",
       "      <th>content_starts_RT</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>content_min_clean</th>\n",
       "      <th>content_hashtags</th>\n",
       "      <th>hashtag_strings</th>\n",
       "      <th>content_mentions</th>\n",
       "      <th>mention_strings</th>\n",
       "      <th>clean_content_stop</th>\n",
       "      <th>clean_content_stop_tokens</th>\n",
       "      <th>case_ratio</th>\n",
       "      <th>sentiment_scores</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>sentiment_class</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-20 12:31:53</th>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>2017-01-20 12:31:53</td>\n",
       "      <td>70523</td>\n",
       "      <td>268372</td>\n",
       "      <td>False</td>\n",
       "      <td>822421390125043713</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>It all begins today! I will see you at 11:00 A...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>begins today see swearing movement continues w...</td>\n",
       "      <td>[begins, today, see, swearing, movement, conti...</td>\n",
       "      <td>0.3304</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:51:25</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>2017-01-20 17:51:25</td>\n",
       "      <td>20125</td>\n",
       "      <td>109640</td>\n",
       "      <td>False</td>\n",
       "      <td>822501803615014918</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>Today we are not merely transferring power fro...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>today merely transferring power one administra...</td>\n",
       "      <td>[today, merely, transferring, power, one, admi...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.919, 'pos': 0.081, 'comp...</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-20 17:51:58</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>2017-01-20 17:51:58</td>\n",
       "      <td>18362</td>\n",
       "      <td>91143</td>\n",
       "      <td>False</td>\n",
       "      <td>822501939267141634</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>power from Washington D.C. and giving it back ...</td>\n",
       "      <td>[#InaugurationDay]</td>\n",
       "      <td>#InaugurationDay</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>power washington c giving back american people</td>\n",
       "      <td>[power, washington, c, giving, back, american,...</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  source                                            content                date  retweet_count  favorite_count is_retweet              id_str  has_RT  starts_RT content_starts_RT                                      clean_content                                  content_min_clean    content_hashtags   hashtag_strings content_mentions mention_strings                                 clean_content_stop                          clean_content_stop_tokens  case_ratio                                   sentiment_scores  compound_score sentiment_class  neg    neu    pos\n",
       "date                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "2017-01-20 12:31:53  Twitter for Android  It all begins today! I will see you at 11:00 A... 2017-01-20 12:31:53          70523          268372      False  822421390125043713   False      False                []  It all begins today! I will see you at 11:00 A...  It all begins today! I will see you at 11:00 A...                  []                                 []                  begins today see swearing movement continues w...  [begins, today, see, swearing, movement, conti...      0.3304  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.0000             pos  0.0  1.000  0.000\n",
       "2017-01-20 17:51:25   Twitter for iPhone  Today we are not merely transferring power fro... 2017-01-20 17:51:25          20125          109640      False  822501803615014918   False      False                []  Today we are not merely transferring power fro...  Today we are not merely transferring power fro...                  []                                 []                  today merely transferring power one administra...  [today, merely, transferring, power, one, admi...      0.0148  {'neg': 0.0, 'neu': 0.919, 'pos': 0.081, 'comp...          0.2144             pos  0.0  0.919  0.081\n",
       "2017-01-20 17:51:58   Twitter for iPhone  power from Washington D.C. and giving it back ... 2017-01-20 17:51:58          18362           91143      False  822501939267141634   False      False                []  power from Washington D.C. and giving it back ...  power from Washington D.C. and giving it back ...  [#InaugurationDay]  #InaugurationDay               []                     power washington c giving back american people  [power, washington, c, giving, back, american,...      0.0778  {'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...          0.3400             pos  0.0  0.844  0.156"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2017-01-20 12:31:53', '2019-06-20 00:12:31'], dtype='datetime64[ns]', name='date', freq=None) None\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'price'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env-ext\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4379\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4380\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4381\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env-ext\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m    945\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m             return com.maybe_box(self, Index.get_value(self, series, key),\n\u001b[0m\u001b[0;32m    947\u001b[0m                                  series, key)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env-ext\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4387\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4388\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4389\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env-ext\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4373\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 4374\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   4375\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.DatetimeEngine._date_check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'price'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\np_datetime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.np_datetime._string_to_dts\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error parsing datetime string \"price\" at position 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env-ext\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env-ext\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown string format:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ('Unknown string format:', 'price')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env-ext\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_maybe_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    957\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env-ext\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py\u001b[0m in \u001b[0;36mget_value_maybe_box\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m    968\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    970\u001b[0m         values = self._engine.get_value(com.values_from_object(series),\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\timestamps.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp.__new__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.convert_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to Timestamp",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7652d1eba851>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m## AM I SURE I WANT TO GET THE PRICE NOW?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mtwitter_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mji\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_stock_prices_for_twitter_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwitter_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstock_price\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwitter_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env-ext\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env-ext\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m    956\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_maybe_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_value_maybe_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'price'"
     ]
    }
   ],
   "source": [
    "### LOAD IN AND PROCESS TWITTER DATA\n",
    "reload([jik,ji])\n",
    "twitter_df,stock_price = ji.load_twitter_df_stock_price()\n",
    "clock = bs.Clock()\n",
    "clock.tic()\n",
    "\n",
    "## LOAD IN RAW TWITTER FILE, PROCESS NLP\n",
    "twitter_df= ji.load_raw_twitter_file()\n",
    "twitter_df = ji.full_twitter_df_processing(twitter_df,\n",
    "                                           cleaned_tweet_col='clean_content')\n",
    "\n",
    "display(twitter_df.head(3))\n",
    "print(twitter_df.index[[0,-1]],twitter_df.index.freq)\n",
    "# twitter_df_backup = twitter_df.copy()\n",
    "# clock.toc()\n",
    "\n",
    "## LOAD IN STOCK PRICE DATA\n",
    "twitter_df = twitter_df.loc[stock_price.index[0]:stock_price.index[-1]];\n",
    "\n",
    "\n",
    "## AM I SURE I WANT TO GET THE PRICE NOW?\n",
    "twitter_df = ji.get_stock_prices_for_twitter_data(twitter_df,stock_price['price'])\n",
    "\n",
    "display(twitter_df.head(3))\n",
    "clock.toc()\n",
    "# ji.plotly_time_series(stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mod4functions_JMI as jmi\n",
    "import functions_combined_BEST as jmi\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "mpl.rcParams['figure.figsize']=(10,8)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Keras preprocessing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Keras neural network basics\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenize=twitter_df\n",
    "\n",
    "class_counts = df_tokenize['delta_price_class'].value_counts()\n",
    "class_counts/len(df_tokenize)\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tokenize.to_csv('twitter_df_tokenized_with_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenize['delta_price_class'].value_counts()['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with class imbalance by sub-sampling\n",
    "\n",
    "df_sampled = df_tokenize.loc[df_tokenize['delta_price_class'] =='pos'].sample(n=class_counts['neg'])\n",
    "df_sampled = pd.concat([df_sampled,df_tokenize.loc[df_tokenize['delta_price_class'] =='neg']], axis=0)\n",
    "display(df_sampled.head())\n",
    "display(df_sampled.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING TEXT DICT FOR FREQUENCY DISTRIBUTIONS\n",
    "from nltk import regexp_tokenize\n",
    "column = 'clean_content_stop'\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "\n",
    "tweets_combined = df_sampled[column]\n",
    "tweets_combined = ' '.join(tweets_combined)\n",
    "tweets_tokenized = regexp_tokenize(tweets_combined, pattern)\n",
    "\n",
    "TEXT = dict()\n",
    "TEXT['tokens'] = tweets_tokenized\n",
    "TEXT['text'] = tweets_combined\n",
    "\n",
    "from nltk import FreqDist\n",
    "freq_tweets = FreqDist(TEXT['tokens'])#df_sampled['clean_content_stop'])\n",
    "with plt.style.context('seaborn-notebook'):\n",
    "    freq_tweets.plot(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(freq_tweets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled['delta_price_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ' '.join(df_tokenize['content_stopped'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled['delta_time'].loc[df_sampled['delta_time']<'1 day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(range(len(df_sampled)))\n",
    "print(df_sampled['content'][i],'\\n')\n",
    "print(df_sampled['content_min_clean'][i],'\\n')\n",
    "print(df_sampled['clean_content'][i],'\\n')\n",
    "print(df_sampled['clean_content_stop'][i],'\\n')\n",
    "print(df_sampled['clean_content_stop_tokens'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column = 'clean_content'\n",
    "# pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "# tweets_combined = df_sampled[column].values\n",
    "# tweets_tokenized = regexp_tokenize(tweets_combined, pattern)\n",
    "# tweets_tokens_combined = ' '.join(tweets_tokenized)\n",
    "# # tweets_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_data = df_tokenize['content_min_clean']\n",
    "# text_data = df_tokenize['content']\n",
    "text_data = df_sampled['content_min_clean'].apply(lambda x: regexp_tokenize(x, pattern))\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "vector_size = 300\n",
    "\n",
    "wv_keras = Word2Vec(text_data, size=vector_size, window=, min_count=2, workers=3)\n",
    "wv_keras.train(text_data,total_examples=wv_keras.corpus_count, epochs=10)\n",
    "\n",
    "wv = wv_keras.wv\n",
    "vocab_size = len(wv_keras.wv.vocab)\n",
    "print(f'There are {vocab_size} words in the word2vec vocabulary, with a vector size {vector_size}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wv_keras.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the vectors in a new matrix\n",
    "word_model = wv_keras\n",
    "vector_size = word_model.wv.vectors[1].shape[0]\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_model.wv.vocab) + 1, vector_size))\n",
    "for i, vec in enumerate(word_model.wv.vectors):\n",
    "  embedding_matrix[i] = vec\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'word2vec_model_twitter.pickle'\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump([word_model,vector_size,embedding_matrix],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of texts to be converted to sequences\n",
    "# sentences_train =text_data # df_tokenize['tokens'].values\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=len(wv.vocab))\n",
    "tokenizer.fit_on_texts(list(text_data)) #tokenizer.fit_on_texts(text_data)\n",
    "\n",
    "word_index = tokenizer.index_word\n",
    "reverse_index = {v:k for k,v in word_index.items()}\n",
    "# word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functions_combined_BEST import train_test_val_split\n",
    "def train_test_val_split(X,y,test_size=0.20,val_size=0.1):\n",
    "    \"\"\"Performs 2 successive train_test_splits to produce a training, testing, and validation dataset\"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    if val_size==0:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "\n",
    "        first_split_size = test_size + val_size\n",
    "        second_split_size = val_size/(test_size + val_size)\n",
    "\n",
    "        X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=first_split_size)\n",
    "\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=second_split_size)\n",
    "\n",
    "        return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tokenize.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss function to use\n",
    "def my_rmse(y_true,y_pred):\n",
    "    \"\"\"RMSE calculation using keras.backend\"\"\"\n",
    "    from keras import backend as kb\n",
    "    sq_err = kb.square(y_pred - y_true)\n",
    "    mse = kb.mean(sq_err,axis=-1)\n",
    "    rmse =kb.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "# CREATING CALLBACKS\n",
    "from keras import callbacks\n",
    "filepath = 'twitterBLP_model1_weights.ep{epoch:02d}-acc{acc:.2f}.hdf5'\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath=filepath, monitor='acc',mode='min',\n",
    "                                       save_best_only=True, verbose=1)\n",
    "early_stop = callbacks.EarlyStopping(monitor='acc',mode='min',patience=1,min_delta=.001,verbose=1)\n",
    "callbacks = [checkpoint]#,early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return integer-encoded sentences\n",
    "from keras.preprocessing import text, sequence\n",
    "X = tokenizer.texts_to_sequences(text_data)\n",
    "X = sequence.pad_sequences(X)\n",
    "\n",
    "y = [1 if x=='pos' else 0  for x in df_sampled['delta_price_class']]\n",
    "# y\n",
    "     # y = df_tokenize['stock_delta_class'].values\n",
    "# reverse_index\n",
    "X_train, X_test, y_train, y_test = train_test_val_split(X, y, test_size=0.1, val_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, optimizers, regularizers\n",
    "vocab_size = len(wv_keras.wv.vocab)\n",
    "model2 = models.Sequential()\n",
    "# embedding_layer = wv.get_keras_embedding(train_embeddings=False)\n",
    "\n",
    "model2.add(layers.Embedding(vocab_size+1,\n",
    "                             vector_size,input_length=X_train.shape[1],\n",
    "                             weights=[embedding_matrix],trainable=False)) \n",
    "#250          \n",
    "model2.add(layers.LSTM(units=250, return_sequences=False))#return_sequences=False))#, kernel_regularizer=regularizers.l2(.01)))\n",
    "# model2.add(layers.LSTM(units=50, return_sequences=False))#return_sequences=False))#, kernel_regularizer=regularizers.l2(.01)))\n",
    "\n",
    "# model2.add(layers.GlobalMaxPooling1D())\n",
    "# model2.add(layers.Dropout(0.2))\n",
    "model2.add(layers.Dense(units=50, activation='relu'))#, activation='tan' # activation='relu'))\n",
    "\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=['acc'])#,'val_acc'])#, callbacks=callbacks)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "FITTING MODEL:\n",
      "------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Clock started at 07/09/19 - 11:10:32 PM\n",
      "Train on 4228 samples, validate on 470 samples\n",
      "Epoch 1/4\n",
      "4228/4228 [==============================] - 53s 12ms/step - loss: 0.6945 - acc: 0.5154 - val_loss: 0.6968 - val_acc: 0.4787\n",
      "\n",
      "Epoch 00001: acc did not improve from 0.49811\n",
      "Epoch 2/4\n",
      "4228/4228 [==============================] - 42s 10ms/step - loss: 0.6910 - acc: 0.5270 - val_loss: 0.6972 - val_acc: 0.5021\n",
      "\n",
      "Epoch 00002: acc did not improve from 0.49811\n",
      "Epoch 3/4\n",
      "4228/4228 [==============================] - 42s 10ms/step - loss: 0.6897 - acc: 0.5303 - val_loss: 0.6947 - val_acc: 0.5106\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.49811\n",
      "Epoch 4/4\n",
      "4228/4228 [==============================] - 42s 10ms/step - loss: 0.6865 - acc: 0.5561 - val_loss: 0.6999 - val_acc: 0.5085\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.49811\n",
      "\tLap #1 done @ 07/09/19 - 11:13:32 PM\tlabel:   completed 4 epochs\tduration: 179.839396 sec)\n",
      "Total Time: 0:02:59.839396.\n",
      "\n",
      " ------------------------------------------------------------------------------------------------------------------------\n",
      "EVALUATE MODEL:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "4698/4698 [==============================] - 38s 8ms/step\n",
      "Training Accuracy:0.561941251596424\n",
      "522/522 [==============================] - 4s 8ms/step\n",
      "Testing Accuracy:0.5287356324122783\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CLASSIFICATION REPORT:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.56      0.55       266\n",
      "           1       0.52      0.50      0.51       256\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       522\n",
      "   macro avg       0.53      0.53      0.53       522\n",
      "weighted avg       0.53      0.53      0.53       522\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[149 117]\n",
      " [129 127]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clock = bs.Clock(verbose=0)\n",
    "print('---'*40)\n",
    "print('\\tFITTING MODEL:')\n",
    "print('---'*40,'\\n')\n",
    "\n",
    "clock.tic('starting keras .fit')\n",
    "\n",
    "num_epochs = 4\n",
    "history = model2.fit(X_train, y_train, epochs=num_epochs, verbose=True, validation_split=0.1,\n",
    "                     callbacks=callbacks,batch_size=300)#, validation_data=(X_val))\n",
    "\n",
    "clock.toc(f'completed {num_epochs} epochs')\n",
    "print('\\n')\n",
    "print('---'*40)\n",
    "print('\\tEVALUATE MODEL:')\n",
    "print('---'*40)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "\n",
    "loss, accuracy = model2.evaluate(X_train, y_train, verbose=True)\n",
    "print(f'Training Accuracy:{accuracy}')\n",
    "\n",
    "loss, accuracy = model2.evaluate(X_test, y_test, verbose=True)\n",
    "print(f'Testing Accuracy:{accuracy}\\n')\n",
    "\n",
    "y_hat_test = model2.predict_classes(X_test)\n",
    "print('---'*40)\n",
    "print('CLASSIFICATION REPORT:')\n",
    "print('---'*40)\n",
    "\n",
    "print(classification_report(y_test,y_hat_test))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, y_hat_test)\n",
    "\n",
    "import bs_ds as bs\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8,4)\n",
    "bs.plot_confusion_matrix(conf_mat,classes=['Stock Increase','Stock Decrease'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functions_combined_BEST import plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters to Search\n",
    "- Data in: \n",
    "    - remove tweets with too long of a delta_time\n",
    "-Keras Layers:\n",
    "    - Dense back to 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model to disk.\n"
     ]
    }
   ],
   "source": [
    "model_json = model2.to_json()\n",
    "with open(\"bestNLPmodel_best_stock_increase_.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model2.save_weights('bestNLPmodel_best_stock_increase_.h5')\n",
    "print(\"saved model to disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Dataframes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-ext",
   "language": "python",
   "name": "learn-env-ext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "25"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
