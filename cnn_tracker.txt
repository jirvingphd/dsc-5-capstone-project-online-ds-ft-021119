NETWORK LAYOUT #1:

from keras.layers import Input, Conv1D,GlobalMaxPooling1D, MaxPooling1D, Dense, Dropout
from keras.models import Model

print('Training model.')
MAX_SEQUENCE_LENGTH = X_train.shape[1]

# train a 1D convnet with global maxpooling
sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')
embedded_sequences = embedding_layer_gl(sequence_input)
## Specify layer parameters
n_units =256
filter_size=3
dropout =0.2
x = Conv1D(n_units, filter_size, activation='relu')(embedded_sequences)
x = Dropout(dropout)(x)
x = MaxPooling1D(filter_size)(x)
x = Conv1D(n_units, filter_size, activation='relu',data_format='channels_first')(x)
x = Dropout(dropout)(x)
x = MaxPooling1D(filter_size)(x)
x = Conv1D(n_units, filter_size, activation='relu')(x)
x = Dropout(dropout)(x)
x = GlobalMaxPooling1D()(x)
x = Dense(n_units, activation='relu')(x) #128
preds = Dense(3, activation='softmax')(x)

model = Model(sequence_input, preds)
model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['acc'])
model.summary()
history = model.fit(X_train, y_train,
                    batch_size=128,
                    epochs=10,
                    validation_data=(X_val,y_val))

1. CNN using GloVe Pretrained Vectors - no retweets
    -Params:
        n_units =256
        filter_size=3
        dropout =0.2
        optimizer = rmsprop
    - Results:
        - Test Accuracy = 0.36
        - conf_matrix = [Decrease:[0.61!,0.38,0.01],NoChange:[0.50,0.47,0.03],Increase[0.55,0.42,0.03] ]







2. CNN using GloVe Pretrained Vectors - no retweets
    - Params:
        ## Specify layer parameters
        n_units =256
        filter_size=4
        dropout =0.2
        optimizer=rmsprop
    - Results:
    
        - Test Accuracy = 0.39
        - conf_matrix = [Decrease:[0.38,0.31,0.31],NoChange:[0.27,0.41,0.32],Increase[0.33,0.29,0.37] ]



######

##CNN+ MORE DENSE LAYERS
from keras.layers import Input, Conv1D,GlobalMaxPooling1D, MaxPooling1D, Dense, Dropout,Flatten
from keras.models import Model

print('Training model.')
MAX_SEQUENCE_LENGTH = X_train.shape[1]

# train a 1D convnet with global maxpooling
sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')
embedded_sequences = embedding_layer_gl(sequence_input)
## Specify layer parameters
n_units =128
filter_size=4
dropout =0.3
x = Conv1D(n_units, filter_size, activation='relu')(embedded_sequences)
x = Dropout(dropout)(x)
x = MaxPooling1D(filter_size)(x)
x = Conv1D(n_units, filter_size, activation='relu',data_format='channels_first')(x)
x = Dropout(dropout)(x)
x = MaxPooling1D(filter_size)(x)
x = Conv1D(n_units, filter_size, activation='relu')(x)

x = Dropout(dropout)(x)
x = GlobalMaxPooling1D()(x)

# x = Flatten()
x = Dense(1024,activation='relu')(x)
x = Dropout(dropout)(x)
x = Dense(512, activation='relu')(x)
x = Dropout(dropout)(x)

x = Dense(n_units, activation='relu')(x) #128
preds = Dense(3, activation='softmax')(x)

model = Model(sequence_input, preds)
model.compile(loss='categorical_crossentropy',
              optimizer="rmsprop",#'adam',#'rmsprop',
              metrics=['acc'])
model.summary()

history = model.fit(X_train, y_train,
                    batch_size=256,#128,
                    epochs=20,
                    validation_data=(X_val,y_val))

- Results:
    - Accuracy = 0.39
    - conf_matrix [[0.67,0.29,0.04],[0.54,0.41,0.05],[0.60,0.28,0.12]]]
